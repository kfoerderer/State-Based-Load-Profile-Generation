{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for generating CHP load profiles\n",
    "\n",
    "The code is structured as follows:\n",
    "- Imports and definition of some basic parameters\n",
    "- Simulation model for creating the data\n",
    "- Datasets using the simulation models\n",
    "- Shared ANN components\n",
    "- State Estimator definition and Training\n",
    "- Classifier definition and Training\n",
    "- Evaluation\n",
    "- Additional code for displaying individual created load profiles\n",
    "\n",
    "Please note:\n",
    "- The code is set up to use CUDA. Remove the .cuda() calls to run on CPU.\n",
    "- Batches are created in individual processes.\n",
    "- To run the evaluation code make sure to install 'jupyter-widgets/jupyterlab-manager' via the command 'jupyter labextension install @jupyter-widgets/jupyterlab-manager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "systems_module_location = \"../../simulation\"\n",
    "\n",
    "import logging\n",
    "\n",
    "# add module location to $PATH if it is missing\n",
    "import sys\n",
    "if systems_module_location not in sys.path:\n",
    "    sys.path.append(systems_module_location)\n",
    "\n",
    "import os\n",
    "    \n",
    "import systems\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.multiprocessing import Manager, Process, Queue\n",
    "import queue\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6, suppress=True, linewidth=150)\n",
    "\n",
    "# Length of a tick in seconds\n",
    "tick_length = 15 * 60\n",
    "# number of seconds in a slot\n",
    "slot_length = 15 * 60\n",
    "\n",
    "# number of slots in a load profile\n",
    "slot_count = 4 * 24\n",
    "\n",
    "# number of slots in a day\n",
    "slots_per_day = 24 * 60 * 60 / slot_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator for creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chpp_heat_storage_dependent_strategy(time, delta_time, action_idxs, chp_plant, heat_storage, weights = [1,1]):\n",
    "    \"\"\"\n",
    "    Change power randomly within bounds of feasible actions\n",
    "    Parameters:\n",
    "        *\n",
    "        weights: (w_<=, w_>), see code\n",
    "    \"\"\"        \n",
    "    current_mode = chp_plant.get_actions()[chp_plant.mode]\n",
    "\n",
    "    actions = chp_plant.get_actions_by_idxs(action_idxs)        \n",
    "    # fallback: action 0\n",
    "    action_choice = list(action_idxs)[0]\n",
    "    # choose an action\n",
    "    if len(actions) > 1:\n",
    "        # if current mode is feasible, stay in this mode with a probability of 2/3\n",
    "        if current_mode.idx in actions and np.random.rand() < 0.66:\n",
    "            action_choice = current_mode.idx\n",
    "\n",
    "        # if current mode isn't feasible or mode should (and can) be changed\n",
    "        else:\n",
    "            non_negative_idxs = [] # modes with th_power >= 0\n",
    "            negative_idxs = [] # modes with th_power < 0\n",
    "            for idx in actions:\n",
    "                if actions[idx].th_power >= 0:\n",
    "                    non_negative_idxs.append(idx)\n",
    "                else:\n",
    "                    negative_idxs.append(idx)\n",
    "            action_idxs = (non_negative_idxs * int(weights[0] * 100 * heat_storage.get_state_of_charge() / max(1,len(non_negative_idxs))) + \n",
    "                          negative_idxs * int(weights[1] * 100 * (1-heat_storage.get_state_of_charge()) / max(1,len(negative_idxs))))\n",
    "            # n,m actions\n",
    "            #\n",
    "            # n actions with th_power <= 0, weighted with: w_<= * 100 * SoC / max(1,n)\n",
    "            # -> for high SoC higher probability\n",
    "            #\n",
    "            #\n",
    "            # m actions with th_power > 0, weighted with: w_> * 100 * (1-SoC) / max(1,m)\n",
    "            # -> for low SoC higher probability\n",
    "            #\n",
    "            #\n",
    "            # The 1 / max(1,n) and 1 / max(1,m) parts eliminate the influence of n and m in the overall probability\n",
    "            #\n",
    "            action_choice = np.random.choice(action_idxs, 1)[0]    \n",
    "\n",
    "    return action_choice\n",
    "\n",
    "class CHPPWithHeatStorageSimulation:\n",
    "\n",
    "    def __init__(self, chp_plant, chpp_strategy, heat_storage, heat_demand, min_soc, max_soc):\n",
    "        self.chp_plant = chp_plant\n",
    "        self.chpp_strategy = chpp_strategy\n",
    "        self.heat_storage = heat_storage\n",
    "        self.heat_demand = heat_demand # array with heat demand for each slot\n",
    "        \n",
    "        self.min_soc = min_soc # for action filtering \n",
    "        self.max_soc = max_soc # for action filtering\n",
    "        \n",
    "        self.actions = chp_plant.get_actions() # dictionary mapping all combinations of actions\n",
    "                \n",
    "        self.load_profile = []\n",
    "        self.infeasibility_slot = -1        \n",
    "                \n",
    "        self.records = []\n",
    "        \n",
    "        \n",
    "    def set_additional_variables(self, min_soc, max_soc):\n",
    "        self.min_soc = min_soc # for action filtering \n",
    "        self.max_soc = max_soc # for action filtering    \n",
    "    \n",
    "    def add_record(self, feasible_actions, action_choice, external_input, debugging_info):\n",
    "        chpp_mode_one_hot = np.zeros(len(self.chp_plant.get_actions()))\n",
    "        chpp_mode_one_hot[self.chp_plant.mode] = 1\n",
    "        record = {\n",
    "            # chpp_mode, chpp_staying_time, hwt_soc, chpp_min_staying_time_0, chpp_min_staying_time_1, hwt_min_soc, hwt_max_soc\n",
    "            'state' :   (*chpp_mode_one_hot, self.chp_plant.staying_time / 24 / 60 / 60,\n",
    "                         round(self.heat_storage.get_state_of_charge(), 4), \n",
    "                         self.chp_plant.actions[0].min_staying_time / 24 / 60 / 60,\n",
    "                         self.chp_plant.actions[1].min_staying_time / 24 / 60 / 60,\n",
    "                         self.min_soc,  self.max_soc),\n",
    "\n",
    "            'feasible_actions' : feasible_actions,\n",
    "            'action_choice' : action_choice,\n",
    "            'external_input' : external_input,\n",
    "            'debugging_info' : debugging_info               \n",
    "        }\n",
    "        self.records.append(record)\n",
    "        \n",
    "    def run(self, tick_length, slot_length, until):\n",
    "        time = 0\n",
    "        sum_of_powers = np.array([0., 0.])\n",
    "        while time < until:\n",
    "        \n",
    "            #\n",
    "            # determine feasible actions\n",
    "            #\n",
    "\n",
    "            # chpp\n",
    "            feasible_chpp_actions = self.chp_plant.get_actions_by_idxs(self.chp_plant.get_feasible_action_idxs(tick_length))\n",
    "\n",
    "            if len(feasible_chpp_actions) > 1:\n",
    "                feasible_chpp_actions = self.heat_storage.filter_actions(lambda action: -action.th_power, feasible_chpp_actions, tick_length, self.min_soc, self.max_soc)\n",
    "            feasible_action_idxs = list(feasible_chpp_actions)\n",
    "\n",
    "            # choose an action\n",
    "            action_choice = self.chpp_strategy(time, tick_length, feasible_action_idxs, self.chp_plant, self.heat_storage, weights=[3,1])\n",
    "                \n",
    "            self.add_record(feasible_action_idxs, action_choice, self.heat_demand[time // slot_length], None)\n",
    "                        \n",
    "            #\n",
    "            # chpp simulation step\n",
    "            #\n",
    "            environment_interaction = self.chp_plant.state_transition(tick_length, action_choice)\n",
    "            \n",
    "            #\n",
    "            # interaction: chpp -> hwt -> demand\n",
    "            #\n",
    "            environment_interaction.th_power += self.heat_demand[time // slot_length]\n",
    "             \n",
    "            #\n",
    "            # hwt simulation step\n",
    "            #\n",
    "            environment_interaction = self.heat_storage.state_transition(tick_length, 0, environment_interaction)\n",
    "            sum_of_powers += np.array([environment_interaction.el_power, environment_interaction.th_power])\n",
    "            \n",
    "            # evaluate feasibility\n",
    "            if self.infeasibility_slot < 0 and \\\n",
    "                (action_choice not in feasible_action_idxs or\n",
    "                   environment_interaction.th_power != 0): #th_power != 0 if either heat is missing or needs to be disposed\n",
    "                \n",
    "                self.infeasibility_slot = time // slot_length\n",
    "\n",
    "            # generate new slot\n",
    "            if time % slot_length == slot_length-tick_length:\n",
    "                # reached end of slot\n",
    "                self.load_profile.append(sum_of_powers[0] / (slot_length/tick_length))\n",
    "                # reset sum\n",
    "                sum_of_powers = np.array([0., 0.])\n",
    "            \n",
    "            time += tick_length\n",
    "            \n",
    "        self.add_record(None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for state transition and classification tasks\n",
    "\n",
    "All datasets are generated on the fly using the simulation model defined above.\n",
    "\n",
    "### Parameters for initializing simulations\n",
    "The following parameters are used to initialize the simulation (and evaluation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of different action dictionaries\n",
    "chpp_staying_times = np.linspace(0, 1, 96+1)\n",
    "chpp_action_sets = []\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        actions = {\n",
    "            0: systems.Action(0, 0, 0, min_staying_time=slot_length*i, max_staying_time=slot_length*slots_per_day),\n",
    "            1: systems.Action(1, -1, -1, min_staying_time=slot_length*j, max_staying_time=slot_length*slots_per_day)\n",
    "        }\n",
    "        chpp_action_sets.append(actions)\n",
    "\n",
    "hwt_capacity = 3 # kWh\n",
    "hwt_socs = np.linspace(0, 1, 101)\n",
    "hwt_absolute_loss = 11.58 * tick_length # per tick, Ws\n",
    "hwt_relative_loss = 4.6 * tick_length / (hwt_capacity * 1000 * 60 * 60)  # per tick, p.u. (Ws / capacity in Ws)\n",
    "hwt_min_socs = np.linspace(0, 0.4, 9)\n",
    "hwt_max_socs = np.linspace(0.6, 1, 9)\n",
    "\n",
    "# load file\n",
    "consumption = pd.read_csv('../../data/household_consumption.csv')\n",
    "# select and scale data\n",
    "HEAT_DEMAND_SCALING_FACTOR = 1/6\n",
    "heat_demand = []\n",
    "heat_demand.append(consumption['winter_th'].values * HEAT_DEMAND_SCALING_FACTOR)\n",
    "heat_demand.append(consumption['interm_th'].values * HEAT_DEMAND_SCALING_FACTOR)\n",
    "heat_demand.append(consumption['summer_th'].values * HEAT_DEMAND_SCALING_FACTOR)\n",
    "heat_demand = np.round(heat_demand,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChppWithHeatStorageTransitionDataset(torch.utils.data.Dataset):\n",
    "    '''    \n",
    "    Generates a dataset for state transition learning    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tick_length, slot_length, slot_count, \n",
    "                 chpp_action_sets, chpp_staying_times, \n",
    "                 hwt_socs, hwt_capacity, hwt_absolute_loss, hwt_relative_loss, hwt_min_socs, hwt_max_socs, heat_demand):\n",
    "        self.tick_length = tick_length\n",
    "        self.slot_length = slot_length\n",
    "        self.slot_count = slot_count\n",
    "        \n",
    "        self.chpp_action_sets = chpp_action_sets      \n",
    "        self.chpp_staying_times = chpp_staying_times\n",
    "        \n",
    "        self.hwt_socs = hwt_socs\n",
    "        self.hwt_capacity = hwt_capacity\n",
    "        self.hwt_absolute_loss = hwt_absolute_loss\n",
    "        self.hwt_relative_loss = hwt_relative_loss\n",
    "        self.hwt_min_socs = hwt_min_socs\n",
    "        self.hwt_max_socs = hwt_max_socs\n",
    "                \n",
    "        self.heat_demand = heat_demand\n",
    "\n",
    "    def set_slot_count(self, slot_count):\n",
    "        self.slot_count = slot_count\n",
    "        \n",
    "        \n",
    "    def index_to_parameter_indices(self, index):\n",
    "        \"\"\"\n",
    "        For on the fly parameter mapping\n",
    "        \"\"\"\n",
    "        hwt_max_charge = index % len(self.hwt_max_socs)        \n",
    "        result = index // len(self.hwt_max_socs)        \n",
    "        \n",
    "        hwt_min_charge = result % len(self.hwt_min_socs)        \n",
    "        result = result // len(self.hwt_min_socs)\n",
    "        \n",
    "        hwt_soc = result % len(self.hwt_socs)        \n",
    "        result = result // len(self.hwt_socs)\n",
    "        \n",
    "        chpp_staying_time = result % len(self.chpp_staying_times) \n",
    "        result = result // len(self.chpp_staying_times)\n",
    "        \n",
    "        chpp_action = result % len(self.chpp_action_sets[0])        \n",
    "        result = result // len(self.chpp_action_sets[0])\n",
    "        \n",
    "        chpp_actions = result % len(self.chpp_action_sets)        \n",
    "        result = result // len(self.chpp_action_sets)\n",
    "        \n",
    "        return (chpp_actions, chpp_action, chpp_staying_time, hwt_soc, hwt_min_charge, hwt_max_charge)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.chpp_action_sets) * len(self.chpp_action_sets[0]) * len(self.chpp_staying_times) *\n",
    "                len(self.hwt_socs) * len(self.hwt_min_socs) * len(self.hwt_max_socs))\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #\n",
    "        # map index to parameters\n",
    "        #\n",
    "        indices = self.index_to_parameter_indices(index)\n",
    "        \n",
    "        chpp_actions = self.chpp_action_sets[int(round(indices[0]))]\n",
    "        chpp_mode_id = int(round(indices[1]))\n",
    "        chpp_mode_id_one_hot = np.zeros(len(chpp_actions))\n",
    "        chpp_mode_id_one_hot[chpp_mode_id] = 1 \n",
    "        chpp_staying_time = round(self.chpp_staying_times[indices[2]], 5)\n",
    "        \n",
    "        hwt_soc = round(self.hwt_socs[indices[3]], 4)        \n",
    "        hwt_min_charge = round(self.hwt_min_socs[indices[4]], 3)\n",
    "        hwt_max_charge = round(self.hwt_max_socs[indices[5]], 3)       \n",
    "        \n",
    "        # heat demand\n",
    "        simulation_heat_demand = []\n",
    "        demand_category = np.random.randint(0, len(self.heat_demand))\n",
    "        demand_start_index = np.random.randint(0, max(1, 60*24 - self.slot_count*self.slot_length/60 - self.slot_length/60/2)) # minutes\n",
    "        for i in range(self.slot_count):\n",
    "            simulation_heat_demand.append(self.heat_demand[demand_category][demand_start_index + np.random.randint(i*self.slot_length/60-self.slot_length/60/2,\n",
    "                                                                                                                    i*self.slot_length/60+self.slot_length/60/2)])\n",
    "        \n",
    "        #\n",
    "        # initialize systems\n",
    "        #\n",
    "        chpp = systems.CHPPlant(chpp_actions, chpp_mode_id, chpp_staying_time*24*60*60, 1/60, 1/60, 1/120, 1/120)\n",
    "        hwt = systems.HeatStorage(self.hwt_capacity, self.hwt_capacity*hwt_soc, 1, 1, self.hwt_relative_loss, self.hwt_absolute_loss)\n",
    "        \n",
    "        # run simulation to advance states\n",
    "        simulation = CHPPWithHeatStorageSimulation(chpp, chpp_heat_storage_dependent_strategy, \n",
    "                                                   hwt, simulation_heat_demand, hwt_min_charge, hwt_max_charge)\n",
    "        simulation.run(self.tick_length, self.slot_length, self.slot_count * self.slot_length)\n",
    "        \n",
    "        input_one_hot = [] # don't start with [0,0] for this recurrent network with readable states\n",
    "        for record in simulation.records:\n",
    "            #print(record)\n",
    "            if record['action_choice'] != None:\n",
    "                one_hot = np.zeros(len(simulation.actions))\n",
    "                one_hot[record['action_choice']] = 1\n",
    "                input_one_hot.append(one_hot)\n",
    "        \n",
    "        return {'input_state': torch.Tensor(simulation.records[0]['state']),\n",
    "                'input_one_hot': torch.Tensor(input_one_hot),\n",
    "                'input_external': torch.Tensor(simulation_heat_demand).view(-1, 1),\n",
    "                'output_states': torch.Tensor([simulation.records[i+1]['state'] for i in range(self.slot_count)])\n",
    "               }\n",
    "    \n",
    "transition_dataset = ChppWithHeatStorageTransitionDataset(tick_length, slot_length, 1,\n",
    "                                                          chpp_action_sets, chpp_staying_times,\n",
    "                                                          hwt_socs, hwt_capacity, hwt_absolute_loss, hwt_relative_loss, hwt_min_socs, hwt_max_socs, heat_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChppWithHeatStorageClassificationDataset(torch.utils.data.Dataset):\n",
    "    '''    \n",
    "    Generates a dataset for classification learning    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tick_length, slot_length, \n",
    "                 chpp_action_sets, chpp_staying_times, \n",
    "                 hwt_socs, hwt_capacity, hwt_absolute_loss, hwt_relative_loss, hwt_min_socs, hwt_max_socs, heat_demand):        \n",
    "        self.tick_length = tick_length\n",
    "        self.slot_length = slot_length\n",
    "        \n",
    "        self.chpp_action_sets = chpp_action_sets      \n",
    "        self.chpp_staying_times = chpp_staying_times\n",
    "        \n",
    "        self.hwt_socs = hwt_socs\n",
    "        self.hwt_capacity = hwt_capacity\n",
    "        self.hwt_absolute_loss = hwt_absolute_loss\n",
    "        self.hwt_relative_loss = hwt_relative_loss\n",
    "        self.hwt_min_socs = hwt_min_socs\n",
    "        self.hwt_max_socs = hwt_max_socs\n",
    "        \n",
    "        self.heat_demand = heat_demand\n",
    "\n",
    "    def sample_index(self):\n",
    "        ''' Randomly samples an index for batch creation '''\n",
    "        \n",
    "        if not hasattr(self, 'weighted_chpp_staying_time_indices'):\n",
    "            # search mode sets for longest possible min_staying_time\n",
    "            max_min_staying_time = 0\n",
    "            for chpp_actions in self.chpp_action_sets:\n",
    "                for key, action in chpp_actions.items():\n",
    "                    if action.min_staying_time > max_min_staying_time:\n",
    "                        max_min_staying_time = action.min_staying_time\n",
    "\n",
    "            self.weighted_chpp_staying_time_indices = []\n",
    "            for i, staying_time in enumerate(self.chpp_staying_times):\n",
    "                self.weighted_chpp_staying_time_indices.append(i)\n",
    "                if staying_time <= max_min_staying_time/24/60/60 + 1/96:\n",
    "                    self.weighted_chpp_staying_time_indices.append(i)\n",
    "        \n",
    "        chpp_actions = np.random.randint(len(self.chpp_action_sets))\n",
    "        idx = chpp_actions\n",
    "        \n",
    "        chpp_action = np.random.randint(len(self.chpp_action_sets[0]))\n",
    "        idx *= len(self.chpp_action_sets[0])\n",
    "        idx += chpp_action\n",
    "        \n",
    "        chpp_staying_time = np.random.choice(self.weighted_chpp_staying_time_indices, 1)[0]\n",
    "        idx *= len(self.chpp_staying_times)\n",
    "        idx += chpp_staying_time\n",
    "        \n",
    "        hwt_min_soc = np.random.randint(len(self.hwt_min_socs))\n",
    "        hwt_max_soc = np.random.randint(len(self.hwt_max_socs))\n",
    "        \n",
    "        weighted_hwt_soc_indices = []\n",
    "        for i, soc in enumerate(self.hwt_socs):\n",
    "            weighted_hwt_soc_indices.append(i)\n",
    "            if soc <= hwt_min_soc + 0.05 or soc >= hwt_max_soc - 0.05:\n",
    "                weighted_hwt_soc_indices.append(i)\n",
    "                \n",
    "        hwt_soc = np.random.choice(weighted_hwt_soc_indices, 1)[0]\n",
    "        idx *= len(self.hwt_socs)        \n",
    "        idx += hwt_soc\n",
    "        \n",
    "        idx *= len(self.hwt_min_socs)\n",
    "        idx += hwt_min_soc\n",
    "        \n",
    "        idx *= len(self.hwt_max_socs)\n",
    "        idx += hwt_max_soc\n",
    "        \n",
    "        return idx\n",
    "                \n",
    "        \n",
    "    def set_slot_count(self, slot_count):\n",
    "        self.slot_count = slot_count\n",
    "        \n",
    "        \n",
    "    def index_to_parameter_indices(self, index):\n",
    "        \"\"\"\n",
    "        For on the fly parameter mapping\n",
    "        index -> indices-tuple (0: chpp_actions, 1: chpp_action, 2: chpp_staying_time, 3: hwt_soc, 4: hwt_min_charge, 5: hwt_max_charge)\n",
    "        \"\"\"\n",
    "        hwt_max_soc = index % len(self.hwt_max_socs)        \n",
    "        result = index // len(self.hwt_max_socs)        \n",
    "        \n",
    "        hwt_min_soc = result % len(self.hwt_min_socs)        \n",
    "        result = result // len(self.hwt_min_socs)\n",
    "        \n",
    "        hwt_soc = result % len(self.hwt_socs)        \n",
    "        result = result // len(self.hwt_socs)\n",
    "        \n",
    "        chpp_staying_time = result % len(self.chpp_staying_times) \n",
    "        result = result // len(self.chpp_staying_times)\n",
    "        \n",
    "        chpp_action = result % len(self.chpp_action_sets[0])        \n",
    "        result = result // len(self.chpp_action_sets[0])\n",
    "        \n",
    "        chpp_actions = result % len(self.chpp_action_sets)        \n",
    "        result = result // len(self.chpp_action_sets)      \n",
    "        \n",
    "        return (chpp_actions, chpp_action, chpp_staying_time, hwt_soc, hwt_min_soc, hwt_max_soc)\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.chpp_action_sets) * len(self.chpp_action_sets[0]) * len(self.chpp_staying_times) *\n",
    "                len(self.hwt_socs) * len(self.hwt_min_socs) * len(self.hwt_max_socs))\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #\n",
    "        # map index to parameters\n",
    "        #\n",
    "        indices = self.index_to_parameter_indices(index)\n",
    "        \n",
    "        chpp_actions = self.chpp_action_sets[int(round(indices[0]))]\n",
    "        chpp_mode_id = int(round(indices[1]))\n",
    "        chpp_mode_id_one_hot = np.zeros(len(chpp_actions))\n",
    "        chpp_mode_id_one_hot[chpp_mode_id] = 1 \n",
    "        chpp_staying_time = round(self.chpp_staying_times[indices[2]], 5)\n",
    "        \n",
    "        hwt_soc = round(self.hwt_socs[indices[3]], 4)        \n",
    "        hwt_min_charge = round(self.hwt_min_socs[indices[4]], 3)\n",
    "        hwt_max_charge = round(self.hwt_max_socs[indices[5]], 3)       \n",
    "        \n",
    "        # heat demand\n",
    "        simulation_heat_demand = [(self.heat_demand[np.random.randint(0, len(self.heat_demand))][np.random.randint(-self.slot_length/60/2, self.slot_length/60/2)])]\n",
    "        \n",
    "        #\n",
    "        # initialize systems\n",
    "        #\n",
    "        chpp = systems.CHPPlant(chpp_actions, chpp_mode_id, chpp_staying_time*24*60*60, 1/60, 1/60, 1/120, 1/120)\n",
    "        hwt = systems.HeatStorage(self.hwt_capacity, self.hwt_capacity*hwt_soc, 1, 1, self.hwt_relative_loss, self.hwt_absolute_loss)\n",
    "\n",
    "        # run simulation to advance states\n",
    "        simulation = CHPPWithHeatStorageSimulation(chpp, chpp_heat_storage_dependent_strategy, \n",
    "                                                   hwt, simulation_heat_demand, hwt_min_charge, hwt_max_charge)\n",
    "        simulation.run(self.tick_length, self.slot_length, self.slot_length)\n",
    "        \n",
    "        feasible_actions_one_hot = np.zeros(len(simulation.actions))\n",
    "        feasible_actions_one_hot[simulation.records[0]['feasible_actions']] = 1\n",
    "        \n",
    "        return {'input_state': torch.Tensor(simulation.records[0]['state']), \n",
    "                'output': torch.Tensor(feasible_actions_one_hot)}\n",
    "    \n",
    "classification_dataset = ChppWithHeatStorageClassificationDataset(tick_length, slot_length,\n",
    "                                                                  chpp_action_sets, chpp_staying_times, \n",
    "                                                                  hwt_socs, hwt_capacity, hwt_absolute_loss, hwt_relative_loss, hwt_min_socs, hwt_max_socs, heat_demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared ANN Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size, output_size = size, size\n",
    "        \n",
    "        self.result_linear = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.result_activation = nn.Tanh()\n",
    "        self.gate_linear = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.gate_activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        result = self.result_linear(input_tensor)\n",
    "        result = self.result_activation(result)\n",
    "        gate = self.gate_linear(input_tensor)\n",
    "        gate = self.gate_activation(gate)\n",
    "        \n",
    "        return result * gate\n",
    "        \n",
    "class GatedResidualLinearBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, internal_size, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size, output_size = size, size\n",
    "        \n",
    "        self.result_linear0 = nn.Linear(input_size, internal_size, bias=bias)\n",
    "        self.result_activation0 = nn.Tanh()\n",
    "        self.result_linear1 = nn.Linear(internal_size, internal_size, bias=bias)\n",
    "        self.result_activation1 = nn.Tanh()\n",
    "        self.result_linear2 = nn.Linear(internal_size, output_size, bias=bias)\n",
    "        \n",
    "        self.gate_linear0 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.gate_activation0 = nn.Tanh()\n",
    "        self.gate_linear1 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.gate_activation1 = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        result = self.result_linear0(input_tensor)\n",
    "        result = self.result_activation0(result)\n",
    "        result = self.result_linear1(result)\n",
    "        result = self.result_activation1(result)\n",
    "        result = self.result_linear2(result)\n",
    "        \n",
    "        gate = self.gate_linear0(input_tensor)\n",
    "        gate = self.gate_activation0(gate)\n",
    "        gate = self.gate_linear1(gate)\n",
    "        gate = self.gate_activation1(gate)\n",
    "        \n",
    "        return result * gate + input_tensor\n",
    "    \n",
    "class LinearBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size, output_size = size, size\n",
    "        \n",
    "        self.layer_0 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.layer_0_activation = nn.ReLU()\n",
    "        self.layer_1 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.layer_1_activation = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.layer_2_activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        result = self.layer_0(input_tensor)\n",
    "        result = self.layer_0_activation(result)\n",
    "        result = self.layer_1(result)\n",
    "        result = self.layer_1_activation(result)\n",
    "        result = self.layer_2(result)\n",
    "        result = self.layer_2_activation(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.uniform_(m.weight, -1, 1)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTransition(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, network_width, state_size):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.input_size = input_size\n",
    "        self.network_width = network_width\n",
    "        \n",
    "        self.tr0 = nn.Linear(input_size, network_width, bias=True)\n",
    "        self.tr1 = LinearBlock(network_width, True)\n",
    "        self.tr1g = LinearBlock(network_width, True)\n",
    "        self.tr2 = LinearBlock(network_width, True)\n",
    "        self.tr2g = LinearBlock(network_width, True)\n",
    "        self.tr3 = LinearBlock(network_width, True)\n",
    "        self.tr3g = LinearBlock(network_width, True)\n",
    "        self.tr4 = LinearBlock(network_width, True)\n",
    "        self.tr4g = LinearBlock(network_width, True)\n",
    "        self.tr5 = LinearBlock(network_width, True)\n",
    "        self.tr5g = LinearBlock(network_width, True)\n",
    "        self.tr6 = nn.Linear(network_width, state_size, bias=True)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_state, input_one_hot, input_external, depth=sys.maxsize):\n",
    "                    \n",
    "        input_tensor = torch.cat((input_state, input_one_hot, input_external), dim=1)\n",
    "        \n",
    "        #print(input_tensor.size())\n",
    "        \n",
    "        state = self.tr0(input_tensor)\n",
    "        if depth > 0:\n",
    "                state = self.tr1(state) * self.tr1g(state) + state\n",
    "        if depth > 1:\n",
    "                state = self.tr2(state) * self.tr2g(state) + state\n",
    "        if depth > 2:\n",
    "                state = self.tr3(state) * self.tr3g(state) + state\n",
    "        if depth > 3:\n",
    "                state = self.tr4(state) * self.tr4g(state) + state\n",
    "        if depth > 4:\n",
    "                state = self.tr5(state) * self.tr5g(state) + state      \n",
    "                \n",
    "        state = self.tr6(state) + input_state\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def initialize_block_weigths(self, block, init_function):\n",
    "        if block == 1:\n",
    "            self.tr1.apply(init_function)\n",
    "            self.tr1g.apply(init_function)\n",
    "        elif block == 2:\n",
    "            self.tr2.apply(init_function)\n",
    "            self.tr2g.apply(init_function)\n",
    "        elif block == 3:\n",
    "            self.tr3.apply(init_function)\n",
    "            self.tr3g.apply(init_function)\n",
    "        elif block == 4:\n",
    "            self.tr4.apply(init_function)\n",
    "            self.tr4g.apply(init_function)\n",
    "        elif block == 5:\n",
    "            self.tr5.apply(init_function)\n",
    "            self.tr5g.apply(init_function)\n",
    "\n",
    "#transition.apply(init_weights) <- problems with NaNs, maybe caused by MSELoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_batch_processes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_batch(batch_queue, batch_size, input_queue, transition_dataset):\n",
    "    ''' Function used by process to create batches. Batches are created according to the parameters \n",
    "    given in the input_queue which specifies the number of unfolding steps. '''\n",
    "    while True:\n",
    "        # set the number of unfolding steps used for creating the next batch      \n",
    "        transition_dataset.set_slot_count(input_queue.get())\n",
    "        \n",
    "        # draw initial states\n",
    "        indices = np.random.randint(len(transition_dataset), size=(batch_size), dtype='int64')\n",
    "        \n",
    "        # create batch\n",
    "        batch = {}\n",
    "        for idx in indices:    \n",
    "            for key, value in transition_dataset[idx].items():\n",
    "                if key in batch:\n",
    "                    batch[key] = torch.cat([batch[key], value.unsqueeze(0)], dim=0)\n",
    "                else:\n",
    "                    batch[key] = value.unsqueeze(0)\n",
    "        batch_queue.put(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "transition_loss_function = nn.MSELoss().cuda()\n",
    "target_function_weights = torch.Tensor([1,1,20,80,10,10,1,1]).cuda()\n",
    "\n",
    "# training parameters\n",
    "batch_size=32\n",
    "training_batch_count = 150001\n",
    "training_summary_at = 1000\n",
    "\n",
    "# evaluation\n",
    "evaluation_at = 10000\n",
    "evaluation_batch_count = 10000\n",
    "evaluation_on_low_training_loss = True\n",
    "best_model_loss = 0.005\n",
    "\n",
    "# regularization\n",
    "l1_crit = nn.L1Loss(reduction='sum').cuda()\n",
    "reg_loss_factor = 1/100000000 #1/10000000\n",
    "\n",
    "# learning rate adaptation\n",
    "learning_rate_initialization = 1e-3\n",
    "learning_rate_loss_factor = 1/1#0#00000\n",
    "learning_rate_decay_after = 20000\n",
    "learning_rate_decay_at = 10000\n",
    "learning_rate_decay_factor = 1/2\n",
    "\n",
    "# modell unfolding\n",
    "unfolding_after = 1000\n",
    "unfolding_at = 1000\n",
    "unfolding_delta = 1\n",
    "unfolding_share = 0\n",
    "unfolding_max_steps = 4\n",
    "single_step_share = 1\n",
    "unfolding_share = unfolding_share / (unfolding_share + single_step_share)\n",
    "\n",
    "# pretraining\n",
    "use_pretraining = False\n",
    "pretraining_initial_depth = 1\n",
    "pretraining_max_depth = 3\n",
    "pretraining_expand_depth_at = 30000\n",
    "\n",
    "# model parameters\n",
    "model_input_size = 2 + 8 + 1 \n",
    "model_width = 64\n",
    "model_output_size = 8\n",
    "model_depth = 3 # pretrain overrides this parameter\n",
    "\n",
    "#\n",
    "# set up\n",
    "#\n",
    "training_run = str(int(time.time()))\n",
    "training_out = \"transition/\" + training_run\n",
    "\n",
    "# create output directory\n",
    "if not os.path.exists(training_out):\n",
    "    os.makedirs(training_out)\n",
    "\n",
    "# set up logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/info.log\".format(training_out)),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "\n",
    "logging.info(\"batch_size: %d\"%batch_size)\n",
    "logging.info(\"learning_rate_initialization: %f, learning_rate_loss_factor: %f, learning_rate_decay_after: %d, learning_rate_decay_at: %d, learning_rate_decay_factor: %f\"%\n",
    "            (learning_rate_initialization, learning_rate_loss_factor, learning_rate_decay_after, learning_rate_decay_at, learning_rate_decay_factor))\n",
    "logging.info('weigths: %s'%str(target_function_weights))\n",
    "logging.info('regularization factor: %.16f'%reg_loss_factor)\n",
    "logging.info(\"unfolding_after: %d, unfolding_at: %d, unfolding_delta: %d, unfolding_share: %f\"%(unfolding_after, unfolding_at, unfolding_delta, unfolding_share))\n",
    "\n",
    "for model_number in range(10):\n",
    "\n",
    "    learning_rate = learning_rate_initialization\n",
    "    \n",
    "    # queue holding batches\n",
    "    multiprocessing_manager = Manager()\n",
    "    transition_batch_queue = multiprocessing_manager.Queue(10)\n",
    "    transition_input_queue = multiprocessing_manager.Queue(20)\n",
    "\n",
    "    # stop the batch creating process if it is already running\n",
    "    for process in transition_batch_processes:\n",
    "        process.terminate()\n",
    "        process.join() # kill zombie process\n",
    "\n",
    "    # start batch creating processes\n",
    "    for i in range(4):\n",
    "        process = Process(target=create_transition_batch, \n",
    "                          args=(transition_batch_queue, batch_size, transition_input_queue, transition_dataset))\n",
    "        process.start()\n",
    "        transition_batch_processes.append(process)\n",
    "\n",
    "\n",
    "    transition = StateTransition(model_input_size, model_width, model_output_size).cuda()\n",
    "    logging.info('---------------------------------')\n",
    "    if use_pretraining:\n",
    "        estimator_depth = pretraining_initial_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d to %d, step at %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          pretraining_initial_depth, pretraining_max_depth, pretraining_expand_depth_at))\n",
    "    \n",
    "    else:\n",
    "        estimator_depth = model_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          estimator_depth))\n",
    "    \n",
    "    transition_solver = optim.Adam(transition.parameters(), lr=5e-3)\n",
    "\n",
    "    worst_loss = -1\n",
    "    worst_loss_unfolding = -1\n",
    "    worst_est = None\n",
    "    worst_target = None\n",
    "    \n",
    "    unfolding_limit= 2\n",
    "    n_unfolding = 0\n",
    "    n_single_step = 0    \n",
    "\n",
    "    force_evaluation = False\n",
    "    for batch_number in range(training_batch_count):\n",
    "\n",
    "        # create input for the batch generation process\n",
    "        try:\n",
    "            while transition_input_queue.full() == False:\n",
    "                # determine number of steps\n",
    "                if batch_number > unfolding_after and np.random.random() < unfolding_share:\n",
    "                    number_training_steps = unfolding_limit + 1 #np.random.randint(2, unfolding_limit+1)\n",
    "                else:\n",
    "                    number_training_steps = 1\n",
    "                transition_input_queue.put_nowait(number_training_steps)\n",
    "        except queue.Full:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            batch = transition_batch_queue.get()\n",
    "        except FileNotFoundError:\n",
    "            batch = transition_batch_queue.get()\n",
    "\n",
    "        state = batch['input_state'].cuda()\n",
    "        batch['input_one_hot'] = batch['input_one_hot'].cuda()\n",
    "        batch['input_external'] = batch['input_external'].cuda()\n",
    "\n",
    "        \n",
    "        transition_loss = torch.zeros(1).cuda()\n",
    "        successful_iterations = 0\n",
    "        for i in range(min(unfolding_limit, batch['input_one_hot'].size(1))):\n",
    "            new_state = transition(state, \n",
    "                                   batch['input_one_hot'][:,i], \n",
    "                                   batch['input_external'][:,i].view(-1,1), \n",
    "                                   estimator_depth)\n",
    "\n",
    "            if torch.isnan(new_state).any():\n",
    "                logging.warning('NaN')\n",
    "                unfolding_limit = max(unfolding_limit - unfolding_delta, 2)\n",
    "                break        \n",
    "\n",
    "            state = new_state\n",
    "            target = batch['output_states'][:,i].cuda()\n",
    "            successful_iterations = i + 1\n",
    "            \n",
    "            transition_loss += transition_loss_function(state * target_function_weights, \n",
    "                                                   target * target_function_weights)\n",
    "\n",
    "        if successful_iterations > 1:\n",
    "            n_unfolding += 1\n",
    "        else:\n",
    "            n_single_step += 1\n",
    "            \n",
    "        transition_loss /= successful_iterations\n",
    "        \n",
    "        est = state                \n",
    "        #transition_loss += transition_loss_function(est * target_function_weights, \n",
    "        #                                           target * target_function_weights)\n",
    "\n",
    "        # regularization\n",
    "        reg_loss = torch.zeros(1).cuda()\n",
    "        for param in transition.parameters():\n",
    "            reg_loss += l1_crit(param, torch.zeros(param.size()).cuda())\n",
    "        transition_loss =  transition_loss + reg_loss * reg_loss_factor\n",
    "\n",
    "        if transition_loss.data > worst_loss:\n",
    "            worst_loss = transition_loss.data\n",
    "            worst_loss_unfolding = batch['input_one_hot'].size(1)-1\n",
    "            worst_est = est\n",
    "            worst_target = target\n",
    "\n",
    "        # training step\n",
    "        transition_solver.zero_grad()\n",
    "        transition_loss.backward(retain_graph=True)    \n",
    "        \n",
    "        # compute sum of gradient norms for summary\n",
    "        grad_norm_sum = 0\n",
    "        if batch_number % training_summary_at == 0:            \n",
    "            for p in transition.parameters():\n",
    "                grad_norm_sum += torch.norm(p.grad.data)\n",
    "\n",
    "        # clip grad norms\n",
    "        nn.utils.clip_grad_norm_(transition.parameters(), 0.1)\n",
    "        transition_solver.step()\n",
    "    \n",
    "        # show training progress\n",
    "        if batch_number % training_summary_at == 0 and batch_number > 0:\n",
    "            \n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Summary:')\n",
    "            logging.info('Batch %d, worst loss %f of %d batches (incl. reg.) (unfolding: %d), learning rate %f @est.-depth %d'%\n",
    "                         (batch_number, worst_loss, training_summary_at, worst_loss_unfolding, learning_rate, estimator_depth))\n",
    "            \n",
    "            logging.info(\"Regularization: %f * %.10f = %.10f loss\"%(reg_loss, reg_loss_factor, reg_loss * reg_loss_factor))\n",
    "            logging.info('unfolding %d, single step %d'%(n_unfolding, n_single_step))\n",
    "\n",
    "            if (reg_loss * reg_loss_factor).data * 10 > worst_loss:                \n",
    "                logging.info('reducing reg_loss_factor')\n",
    "                reg_loss_factor *= 0.1\n",
    "                \n",
    "            logging.info('Sum of grad norms of most recent batch: %f'%grad_norm_sum)\n",
    "                                \n",
    "            # do learn rate adaption\n",
    "            learning_rate = min(learning_rate_initialization, max(1e-16, min(float(worst_loss)*learning_rate_loss_factor, learning_rate)))\n",
    "            for param_group in transition_solver.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "            \n",
    "            if worst_loss < best_model_loss:\n",
    "                force_evaluation = evaluation_on_low_training_loss\n",
    "            \n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')\n",
    "            \n",
    "        # conduct model evaluation    \n",
    "        if force_evaluation or (batch_number % evaluation_at == 0 and batch_number > 0):\n",
    "            force_evaluation = False            \n",
    "\n",
    "            # do evaluation\n",
    "            transition.eval()\n",
    "\n",
    "            for evaluation_batch_number in range(evaluation_batch_count):\n",
    "                \n",
    "                # create input for the batch generation process\n",
    "                try:\n",
    "                    while transition_input_queue.full() == False:\n",
    "                        number_training_steps = 1    \n",
    "                        transition_input_queue.put_nowait(number_training_steps)\n",
    "                except queue.Full:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    batch = transition_batch_queue.get()\n",
    "                except FileNotFoundError:\n",
    "                    batch = transition_batch_queue.get()\n",
    "                \n",
    "                state = batch['input_state'].cuda()\n",
    "                batch['input_one_hot'] = batch['input_one_hot'].cuda()\n",
    "                batch['input_external'] = batch['input_external'].cuda()\n",
    "                \n",
    "                est = transition(state, \n",
    "                                   batch['input_one_hot'][:,0], \n",
    "                                   batch['input_external'][:,0].view(-1,1), \n",
    "                                   estimator_depth)\n",
    "                target = batch['output_states'][:,0].cuda()\n",
    "                transition_loss = transition_loss_function(est * target_function_weights, \n",
    "                                                           target * target_function_weights)\n",
    "\n",
    "                if transition_loss.data > worst_loss:\n",
    "                    worst_loss = transition_loss.data\n",
    "                    worst_est = est\n",
    "                    worst_target = target\n",
    "\n",
    "            # finished\n",
    "            transition.train()\n",
    "\n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Evaluation:')\n",
    "            logging.info('Batch %d, worst loss %f of %d batches (without reg.) @est.-depth %d'%\n",
    "                 (batch_number, worst_loss, evaluation_batch_count, estimator_depth))\n",
    "\n",
    "            if worst_loss < best_model_loss and batch_number > 1:                \n",
    "                best_model_loss = worst_loss\n",
    "                # save modell\n",
    "                file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + \\\n",
    "                            '_transition_' + str(batch_number) + '.pth'\n",
    "                logging.info(\"New best loss %f, saved to file %s\"%(worst_loss,file_name))\n",
    "                torch.save(transition.state_dict(), file_name)\n",
    "\n",
    "                logging.info('Target')\n",
    "                logging.info(worst_target.cpu().numpy())\n",
    "                logging.info('Estimator output')\n",
    "                logging.info(worst_est.detach().cpu().numpy())\n",
    "\n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')    \n",
    "        \n",
    "        # expand model depth when pretraining \n",
    "        if use_pretraining and batch_number > 0 and batch_number % pretraining_expand_depth_at == 0:\n",
    "            if estimator_depth < pretraining_max_depth:\n",
    "                estimator_depth += 1\n",
    "                transition.initialize_block_weigths(estimator_depth, init_weights)\n",
    "        \n",
    "        # adapt learning rate            \n",
    "        if batch_number > learning_rate_decay_after and batch_number % learning_rate_decay_at == 0:\n",
    "            learning_rate = learning_rate * learning_rate_decay_factor\n",
    "            \n",
    "        # adapt unfolding\n",
    "        if batch_number > unfolding_after and batch_number % unfolding_at == 0:\n",
    "            unfolding_limit = min(unfolding_limit + unfolding_delta, min(unfolding_max_steps, slot_count-1))\n",
    "            \n",
    "    # finished training\n",
    "    file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + '_transition_final.pth'\n",
    "    logging.info(\"Finished training, saved to file %s\"%(file_name))\n",
    "    torch.save(transition.state_dict(), file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, network_width, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.network_width = network_width\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.cl0 = nn.Linear(state_size, network_width)\n",
    "        self.cl1 = LinearBlock(network_width, bias=True)\n",
    "        self.cl2 = LinearBlock(network_width, bias=True)\n",
    "        self.cl3 = LinearBlock(network_width, bias=True)\n",
    "        self.cl4 = LinearBlock(network_width, bias=True)\n",
    "        self.cl5 = LinearBlock(network_width, bias=True)\n",
    "        \n",
    "        self.clbn0 = nn.BatchNorm1d(network_width)\n",
    "        self.clbn1 = nn.BatchNorm1d(network_width)\n",
    "        \n",
    "        self.cl0o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl1o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl2o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl3o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl4o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl5o = nn.Linear(network_width, output_size, bias=True)\n",
    "             \n",
    "        \n",
    "    def forward(self, input_state, depth=sys.maxsize):\n",
    "        #input_power = input_power.unsqueeze(1)\n",
    "         \n",
    "        out = self.cl0(input_state)\n",
    "        #out = self.cl0a(out)\n",
    "        if depth > 0:\n",
    "            out = self.cl1(out)\n",
    "        if depth > 1:\n",
    "            out = self.cl2(out)\n",
    "        if depth > 2:\n",
    "            out = self.cl3(out)\n",
    "        if depth > 3:\n",
    "            out = self.cl4(out)\n",
    "        if depth > 4:\n",
    "            out = self.cl5(out)\n",
    "            \n",
    "            \n",
    "        if depth == 0:\n",
    "            out = self.cl0o(out)\n",
    "        elif depth == 1:\n",
    "            out = self.cl1o(out)\n",
    "        elif depth == 2:\n",
    "            out = self.cl2o(out)\n",
    "        elif depth == 3:\n",
    "            out = self.cl3o(out)\n",
    "        elif depth == 4:\n",
    "            out = self.cl4o(out)\n",
    "        else:\n",
    "            out = self.cl5o(out)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def initialize_block_weigths(self, block, init_function):\n",
    "        if block == 1:\n",
    "            self.cl1.apply(init_function)\n",
    "            self.cl1o.apply(init_function)\n",
    "        elif block == 2:\n",
    "            self.cl2.apply(init_function)\n",
    "            self.cl2o.apply(init_function)\n",
    "        elif block == 3:\n",
    "            self.cl3.apply(init_function)\n",
    "            self.cl3o.apply(init_function)\n",
    "        elif block == 4:\n",
    "            self.cl4.apply(init_function)\n",
    "            self.cl4o.apply(init_function)\n",
    "        elif block == 5:\n",
    "            self.cl5.apply(init_function)\n",
    "            self.cl5o.apply(init_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_batch_processes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_batch(batch_queue, batch_size, classification_dataset):\n",
    "    ''' Function used by process to create batches '''\n",
    "    while True:\n",
    "        # draw initial states\n",
    "        indices = [classification_dataset.sample_index() for i in range(batch_size)]\n",
    "        \n",
    "        # create batch\n",
    "        batch = {}\n",
    "        for idx in indices:    \n",
    "            for key, value in classification_dataset[idx].items():\n",
    "                if key in batch:\n",
    "                    batch[key] = torch.cat([batch[key], value.unsqueeze(0)], dim=0)\n",
    "                else:\n",
    "                    batch[key] = value.unsqueeze(0)\n",
    "        batch_queue.put(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "classifier_loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1]*2)).cuda() #nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "#training parameters\n",
    "batch_size=32\n",
    "training_batch_count = 100001 #100001\n",
    "training_summary_at = 1000\n",
    "\n",
    "# regularization\n",
    "l1_crit = nn.L1Loss(reduction='sum').cuda()\n",
    "reg_loss_factor = 0.0001\n",
    "\n",
    "# evaluation\n",
    "evaluation_at = 10000\n",
    "evaluation_batch_count = 10000\n",
    "evaluation_on_low_training_loss = True\n",
    "\n",
    "# learning rate adaptation\n",
    "learning_rate_initialization = 1e-3\n",
    "learning_rate_loss_factor = 1/100#00000\n",
    "learning_rate_decay_after = 30000\n",
    "learning_rate_decay_at = 10000\n",
    "learning_rate_decay_factor = 1/4\n",
    "\n",
    "# pretraining\n",
    "use_pretraining = False\n",
    "pretraining_initial_depth = 1\n",
    "pretraining_max_depth = 2\n",
    "pretraining_expand_depth_at = 30000\n",
    "\n",
    "# model parameters\n",
    "model_input_size = 8\n",
    "model_width = 64\n",
    "model_output_size = 2\n",
    "model_depth = 1 # pretraining overrides this parameter\n",
    "\n",
    "best_model_loss = 0.15\n",
    "\n",
    "#\n",
    "# set  up\n",
    "#\n",
    "training_run = str(int(time.time()))\n",
    "training_out = \"classifier/\" + training_run\n",
    "\n",
    "# create output directory\n",
    "if not os.path.exists(training_out):\n",
    "    os.makedirs(training_out)\n",
    "\n",
    "# set up logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/info.log\".format(training_out)),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "\n",
    "logging.info(\"batch_size: %d\"%batch_size)\n",
    "logging.info(\"learning_rate_initialization: %f, learning_rate_loss_factor: %f, learning_rate_decay_after: %d, learning_rate_decay_at: %d, learning_rate_decay_factor: %f\"%\n",
    "            (learning_rate_initialization, learning_rate_loss_factor, learning_rate_decay_after, learning_rate_decay_at, learning_rate_decay_factor))\n",
    "logging.info('regularization factor: %.10f'%reg_loss_factor)\n",
    "\n",
    "for model_number in range(10):\n",
    "    \n",
    "    learning_rate = learning_rate_initialization\n",
    "    \n",
    "    # queue holding batches\n",
    "    multiprocessing_manager = Manager()\n",
    "    classification_batch_queue = multiprocessing_manager.Queue(10)\n",
    "\n",
    "     # stop the batch creating process if it is already running\n",
    "    for process in classification_batch_processes:\n",
    "        process.terminate()\n",
    "        process.join() # kill zombie process\n",
    "\n",
    "    # start batch creating processes\n",
    "    for i in range(4):\n",
    "        process = Process(target=create_classification_batch, \n",
    "                          args=(classification_batch_queue, batch_size, classification_dataset))\n",
    "        process.start()\n",
    "        classification_batch_processes.append(process)\n",
    "\n",
    "    \n",
    "    classifier = Classifier(model_input_size, model_width, model_output_size).cuda()\n",
    "    classifier.apply(init_weights)\n",
    "    logging.info('---------------------------------')\n",
    "    if use_pretraining:    \n",
    "        classifier_depth = pretraining_initial_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d to %d, step at %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          pretraining_initial_depth, pretraining_max_depth, pretraining_expand_depth_at))\n",
    "    \n",
    "    else:\n",
    "        classifier_depth = model_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          classifier_depth))\n",
    "    \n",
    "    classifier_solver = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "    \n",
    "    worst_loss = -1\n",
    "    worst_est = None\n",
    "    worst_target = None\n",
    "\n",
    "    force_evaluation = False\n",
    "    for batch_number in range(training_batch_count):\n",
    "        \n",
    "        batch = classification_batch_queue.get()\n",
    "        \n",
    "        input_state = batch['input_state'].cuda()\n",
    "        out = classifier(input_state, classifier_depth)\n",
    "\n",
    "        target = batch['output'].cuda()\n",
    "        \n",
    "        # {0,1} -> {0.01. 0.99}\n",
    "        target = (target * 49 + 0.5) / 50 # 9 ... / 10 for {0.05, 0.95}\n",
    "        \n",
    "        classifier_loss = classifier_loss_function(out, target)\n",
    "        \n",
    "        reg_loss = 0\n",
    "        for param in classifier.parameters():\n",
    "            reg_loss += l1_crit(param, torch.zeros(param.size()).cuda())\n",
    "            \n",
    "        classifier_loss += reg_loss * reg_loss_factor\n",
    "            \n",
    "        if classifier_loss.data > worst_loss:\n",
    "            worst_loss = classifier_loss.data\n",
    "            worst_est = out\n",
    "            worst_target = target\n",
    "\n",
    "        classifier_solver.zero_grad()\n",
    "        classifier_loss.backward(retain_graph=True)    \n",
    "        \n",
    "        \n",
    "        # compute sum of gradient norms for summary\n",
    "        grad_norm_sum = 0\n",
    "        if batch_number % training_summary_at == 0:            \n",
    "            for p in classifier.parameters():\n",
    "                grad_norm_sum += torch.norm(p.grad.data)\n",
    "                \n",
    "        nn.utils.clip_grad_norm_(classifier.parameters(), 0.1)\n",
    "        classifier_solver.step()\n",
    "            \n",
    "        # show training progress\n",
    "        if batch_number % training_summary_at == 0 and batch_number > 0:\n",
    "            \n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Summary:')\n",
    "            logging.info('Batch %d, worst loss %f (incl. reg.) of %d batches, learning rate %f @cl.-depth %d'%\n",
    "                         (batch_number, worst_loss, training_summary_at, learning_rate, classifier_depth))\n",
    "            \n",
    "            logging.info(\"Regularization: %f * %.10f = %.10f\"%(reg_loss, reg_loss_factor, reg_loss * reg_loss_factor))\n",
    "            \n",
    "            if (reg_loss * reg_loss_factor).data * 10 > worst_loss:\n",
    "                logging.info('reducing reg_loss_factor')\n",
    "                reg_loss_factor *= 0.1\n",
    "                \n",
    "            logging.info('Sum of grad norms: %f'%grad_norm_sum)\n",
    "                            \n",
    "            # do learn rate adaption\n",
    "            learning_rate = min(learning_rate_initialization, max(1e-16, min(worst_loss*learning_rate_loss_factor, learning_rate)))\n",
    "            for param_group in classifier_solver.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "            \n",
    "            if worst_loss < best_model_loss:\n",
    "                force_evaluation = evaluation_on_low_training_loss\n",
    "            \n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')\n",
    "            \n",
    "        # conduct model evaluation    \n",
    "        if force_evaluation or (batch_number % evaluation_at == 0 and batch_number > 0):\n",
    "            force_evaluation = False\n",
    "\n",
    "            # do evaluation\n",
    "            classifier.eval()\n",
    "\n",
    "            for evaluation_batch_number in range(evaluation_batch_count):\n",
    "                batch = classification_batch_queue.get()\n",
    "\n",
    "                input_state = batch['input_state'].cuda()\n",
    "                out = classifier(input_state, classifier_depth)\n",
    "                target = batch['output'].cuda()\n",
    "                \n",
    "                # {0,1} -> {0.01. 0.99}\n",
    "                target = (target * 49 + 0.5) / 50 # 9 ... / 10 for {0.05, 0.95}\n",
    "                \n",
    "                classifier_loss = classifier_loss_function(out, target)\n",
    "\n",
    "                if classifier_loss.data > worst_loss:\n",
    "                    worst_loss = classifier_loss.data\n",
    "                    worst_est = out\n",
    "                    worst_target = target\n",
    "\n",
    "            # finished\n",
    "            classifier.train()\n",
    "\n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Evaluation:')\n",
    "            logging.info('Batch %d, worst loss %f (without reg.) of %d batches @cl.-depth %d'%\n",
    "                 (batch_number, worst_loss, evaluation_batch_count, classifier_depth))\n",
    "\n",
    "            if worst_loss < best_model_loss and batch_number > 0:                \n",
    "                best_model_loss = worst_loss\n",
    "                # save modell\n",
    "                file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + \\\n",
    "                            '_classifier_' + str(batch_number) + '.pth'\n",
    "                logging.info(\"New best loss %f, saved to file %s\"%(worst_loss,file_name))\n",
    "                torch.save(classifier.state_dict(), file_name)\n",
    "\n",
    "                logging.info('Target')\n",
    "                logging.info(worst_target.cpu().numpy())\n",
    "                logging.info('Classifier output')\n",
    "                logging.info(torch.sigmoid(worst_est.detach()).cpu().numpy())\n",
    "\n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')                    \n",
    "        \n",
    "        # expand model depth when pretraining \n",
    "        if use_pretraining and batch_number > 0 and batch_number % pretraining_expand_depth_at == 0:\n",
    "            if classifier_depth < pretraining_max_depth:\n",
    "                classifier_depth += 1\n",
    "                classifier.initialize_block_weigths(classifier_depth, init_weights)\n",
    "        \n",
    "        # adapt learning rate\n",
    "        if batch_number > learning_rate_decay_after and batch_number % learning_rate_decay_at == 0:\n",
    "            learning_rate = learning_rate * learning_rate_decay_factor\n",
    "                                     \n",
    "    # finished training\n",
    "    file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + '_classifier_final.pth'\n",
    "    logging.info(\"Finished training, saved to file %s\"%(file_name))\n",
    "    torch.save(classifier.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Set up the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models and set evaluation mode\n",
    "\n",
    "# state transition\n",
    "transition = StateTransition(8 + 2 + 1, 64, 8)\n",
    "transition.load_state_dict(torch.load('transition/1554653688_0.0048/1554676378_5_transition_110000.pth'))\n",
    "estimator_depth = 3\n",
    "\n",
    "transition.eval()\n",
    "\n",
    "# classifier\n",
    "classifier = Classifier(8, 64, 2)\n",
    "classifier.load_state_dict(torch.load('classifier/1553275201_0.151/1553276256_0_classifier_70000.pth'))  \n",
    "classifier_depth = 2\n",
    "\n",
    "classifier.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_evaluate_load_profile(\n",
    "                  chpp_actions, chpp_mode_id, chpp_staying_time, hwt_capacity, hwt_soc, hwt_absolute_loss, hwt_relative_loss, hwt_min_soc, hwt_max_soc, simulation_heat_demand, \n",
    "                  series_length, slot_length, tick_length, \n",
    "                  buffers, confidence,\n",
    "                  transition, estimator_depth, classifier, classifier_depth, state_mapping):\n",
    "    '''\n",
    "    \n",
    "    generates load profiles using the ANNs and evaluates the result.\n",
    "    \n",
    "    State post-processing:\n",
    "        - discretization\n",
    "    \n",
    "    '''        \n",
    "    chpp_mode_one_hot = np.zeros(len(chpp_actions))\n",
    "    chpp_mode_one_hot[chpp_mode_id] = 1\n",
    "    \n",
    "    # chpp_mode, chpp_staying_time, hwt_soc, chpp_min_staying_time_0, chpp_min_staying_time_1, hwt_min_soc, hwt_max_soc\n",
    "    current_state = torch.Tensor([*chpp_mode_one_hot, \n",
    "                                 chpp_staying_time, \n",
    "                                 hwt_soc,\n",
    "                                 chpp_actions[0].min_staying_time / 24 / 60 / 60,\n",
    "                                 chpp_actions[1].min_staying_time / 24 / 60 / 60,\n",
    "                                 hwt_min_soc,\n",
    "                                 hwt_max_soc]).unsqueeze(0)\n",
    "    \n",
    "    buffer = torch.Tensor([0, 0, \n",
    "                           0, \n",
    "                           0, \n",
    "                           buffers['min_staying_time'][0] / 24 / 60 / 60, \n",
    "                           buffers['min_staying_time'][1] / 24 / 60 / 60, \n",
    "                           buffers['min_charge'], \n",
    "                           buffers['max_charge']]).unsqueeze(0)\n",
    "    \n",
    "    # generate data\n",
    "    generated_states = []    \n",
    "    generated_data = None\n",
    "    action_history = []\n",
    "    for i in range(series_length):\n",
    "        generated_states.append(current_state.data.numpy()[0])\n",
    "        \n",
    "        # classify\n",
    "        out = classifier(current_state + buffer, classifier_depth)\n",
    "        if generated_data is None:\n",
    "            generated_data = out\n",
    "        else:\n",
    "            generated_data = torch.cat((generated_data, out), dim = 0)                \n",
    "            \n",
    "        # choose action\n",
    "        feasible_actions = np.where(torch.sigmoid(out.squeeze()).data.numpy() >= confidence)[0]\n",
    "        if len(feasible_actions) > 0:\n",
    "            action = np.random.choice(feasible_actions, 1)[0]\n",
    "        else:\n",
    "            action = np.argmax(torch.sigmoid(out.squeeze()).data.numpy())\n",
    "            #print('WARNING: all actions infeasible, defaulting to %d'%action)\n",
    "        \n",
    "        action_history.append(action)\n",
    "        \n",
    "        if i == len(simulation_heat_demand):\n",
    "            break\n",
    "\n",
    "        action_one_hot = np.zeros(out.size(1))\n",
    "        action_one_hot[action] = 1\n",
    "        input_one_hot = torch.Tensor(action_one_hot).view(1,-1)\n",
    "        input_external = torch.Tensor([simulation_heat_demand[i-1]]).view(1,-1)        \n",
    "\n",
    "        current_state = transition(current_state, input_one_hot, input_external, estimator_depth)\n",
    "        \n",
    "        #\n",
    "        # <state post-processing>\n",
    "        #\n",
    "        # (discretization)\n",
    "        #\n",
    "        current_state[:,0] = torch.Tensor([state_mapping['discrete_one_hot'][np.digitize(current_state[:,0].detach().numpy(), \n",
    "                                                                                         state_mapping['discrete_one_hot_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,1] = torch.Tensor([state_mapping['discrete_one_hot'][np.digitize(current_state[:,1].detach().numpy(), \n",
    "                                                                                         state_mapping['discrete_one_hot_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,2] = torch.Tensor([state_mapping['discrete_staying_times'][np.digitize(current_state[:,2].detach().numpy(), \n",
    "                                                                                               state_mapping['discrete_staying_times_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,3] = torch.Tensor([state_mapping['discrete_socs'][np.digitize(current_state[:,3].detach().numpy(), \n",
    "                                                                                      state_mapping['discrete_socs_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,4] = torch.Tensor([state_mapping['discrete_staying_times'][np.digitize(current_state[:,4].detach().numpy(), \n",
    "                                                                                               state_mapping['discrete_staying_times_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,5] = torch.Tensor([state_mapping['discrete_staying_times'][np.digitize(current_state[:,5].detach().numpy(),\n",
    "                                                                                               state_mapping['discrete_staying_times_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,6] = torch.Tensor([state_mapping['discrete_soc_bounds'][np.digitize(current_state[:,6].detach().numpy(), \n",
    "                                                                                            state_mapping['discrete_soc_bounds_bins'])]]).unsqueeze(0)\n",
    "        current_state[:,7] = torch.Tensor([state_mapping['discrete_soc_bounds'][np.digitize(current_state[:,7].detach().numpy(), \n",
    "                                                                                            state_mapping['discrete_soc_bounds_bins'])]]).unsqueeze(0)\n",
    "        #\n",
    "        # </state post-processing>\n",
    "        #\n",
    "\n",
    "    # test if generated profile is feasible\n",
    "    \n",
    "    def predetermined_strategy(time, delta_time, action_idxs, chpp, hwt, weights):\n",
    "        return action_history[time // slot_length]\n",
    "    \n",
    "    chpp = systems.CHPPlant(chpp_actions, chpp_mode_id, chpp_staying_time*24*60*60, 1/60, 1/60, 1/120, 1/120)\n",
    "    hwt = systems.HeatStorage(hwt_capacity, hwt_capacity*hwt_soc, 1, 1, hwt_relative_loss, hwt_absolute_loss)\n",
    "    \n",
    "    # run simulation\n",
    "    simulation = CHPPWithHeatStorageSimulation(chpp, predetermined_strategy, hwt, simulation_heat_demand, hwt_min_soc, hwt_max_soc)\n",
    "    simulation.run(tick_length, slot_length, series_length * slot_length)\n",
    "    \n",
    "    return [simulation.infeasibility_slot, np.array(simulation.load_profile), generated_states, generated_data, simulation.records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_feasibility_of_load_profile(chpp_actions, chpp_mode_id, chpp_staying_time, \n",
    "                                          hwt_capacity, hwt_soc, hwt_absolute_loss, hwt_relative_loss, hwt_min_soc, hwt_max_soc, simulation_heat_demand, \n",
    "                                          series_length, slot_length, tick_length, \n",
    "                                          buffers, confidence,\n",
    "                                          transition, estimator_depth, classifier, classifier_depth, state_mapping, action_history):\n",
    "    \n",
    "    # test if generated profile is feasible    \n",
    "    def predetermined_strategy(time, delta_time, action_idxs, chpp, hwt, weights):\n",
    "        return action_history[time // slot_length]\n",
    "    \n",
    "    chpp = systems.CHPPlant(chpp_actions, chpp_mode_id, chpp_staying_time*24*60*60, 1/60, 1/60, 1/120, 1/120)\n",
    "    hwt = systems.HeatStorage(hwt_capacity, hwt_capacity*hwt_soc, 1, 1, hwt_relative_loss, hwt_absolute_loss)\n",
    "    \n",
    "    # run simulation\n",
    "    simulation = CHPPWithHeatStorageSimulation(chpp, predetermined_strategy, \n",
    "                                                         hwt, simulation_heat_demand, hwt_min_soc, hwt_max_soc)\n",
    "    simulation.run(tick_length, slot_length, series_length * slot_length)\n",
    "    \n",
    "    return simulation.infeasibility_slot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1924)\n",
    "\n",
    "confidence = 0.95\n",
    "\n",
    "#\n",
    "# Elements of the state are discretized\n",
    "#\n",
    "state_mapping = {\n",
    "    # discretization\n",
    "    'discrete_socs': np.linspace(0, 1, 1001),\n",
    "    'discrete_one_hot': np.array([0,1]),    \n",
    "    'discrete_staying_times': np.linspace(0, 1, 96+1),\n",
    "    'discrete_soc_bounds': np.append(hwt_min_socs, hwt_max_socs),\n",
    "}\n",
    "\n",
    "state_mapping.update({\n",
    "    'discrete_socs_bins': [(a + b) / 2 for a, b in zip(state_mapping['discrete_socs'][:-1], state_mapping['discrete_socs'][1:])],\n",
    "    'discrete_one_hot_bins': [(a + b) / 2 for a, b in zip(state_mapping['discrete_one_hot'][:-1], state_mapping['discrete_one_hot'][1:])],\n",
    "    'discrete_staying_times_bins': [(a + b) / 2 for a, b in zip(state_mapping['discrete_staying_times'][:-1], state_mapping['discrete_staying_times'][1:])],\n",
    "    'discrete_soc_bounds_bins': [(a + b) / 2 for a, b in zip(state_mapping['discrete_soc_bounds'][:-1], state_mapping['discrete_soc_bounds'][1:])]    \n",
    "})\n",
    "    \n",
    "# number of threads used for simulation\n",
    "simulation_thread_count = 1 # (more than 1 is slower)\n",
    "# number of simulations to run\n",
    "simulation_count = 1000\n",
    "\n",
    "# set up initial states for the simulation runs\n",
    "force_replace = False\n",
    "\n",
    "buffers = {'min_staying_time': (0,0), 'min_charge':0, 'max_charge':0} #(SLOT_LENGTH, SLOT_LENGTH),\n",
    "#buffers = {'min_staying_time': (0,0), 'min_charge':0.05, 'max_charge':-0.05} #(SLOT_LENGTH, SLOT_LENGTH),\n",
    "#buffers = {'min_staying_time': (0,0), 'min_charge':0.1, 'max_charge':-0.1} #(SLOT_LENGTH, SLOT_LENGTH),\n",
    "\n",
    "chpp_actions_choices = np.random.choice(range(len(chpp_action_sets)), simulation_count, replace=(simulation_count>len(chpp_action_sets) or force_replace))\n",
    "chpp_mode_id_choices = np.random.choice(range(len(chpp_action_sets[0])), simulation_count, replace=(simulation_count>len(chpp_action_sets[0]) or force_replace))  \n",
    "chpp_staying_time_choices = np.random.choice(chpp_staying_times, simulation_count, replace=(simulation_count>len(chpp_staying_times) or force_replace))  \n",
    "\n",
    "hwt_soc_choices = np.random.choice(np.linspace(0.01,0.99,99), simulation_count, replace=(simulation_count>99 or force_replace)) \n",
    "# please note that these choices are adapted below\n",
    "hwt_min_soc_choices = np.random.choice(hwt_min_socs, simulation_count, replace=(simulation_count>len(hwt_min_socs) or force_replace))\n",
    "hwt_max_soc_choices = np.random.choice(hwt_max_socs, simulation_count, replace=(simulation_count>len(hwt_max_socs) or force_replace))\n",
    "\n",
    "# winter, int., summer\n",
    "hwt_min_soc_from_demand = [0.25, 0.2, 0.15]\n",
    "hwt_max_soc_from_demand = [0.85, 0.8, 0.75]\n",
    "\n",
    "demand_id_choices = np.random.choice(list(range(len(heat_demand))), simulation_count, replace=(simulation_count>len(heat_demand)))\n",
    "simulation_heat_demands = []\n",
    "for i, demand_id in enumerate(demand_id_choices):\n",
    "    # adapt buffers\n",
    "    hwt_min_soc_choices[i] = max(hwt_min_soc_from_demand[demand_id], hwt_min_soc_choices[i])\n",
    "    hwt_max_soc_choices[i] = min(hwt_max_soc_from_demand[demand_id], hwt_max_soc_choices[i])\n",
    "    # generate heat demand series\n",
    "    demand_series = []\n",
    "    seconds = 0\n",
    "    for i in range(slot_count):\n",
    "        demand_series.append(heat_demand[demand_id][np.random.randint(-slot_length/60/2, slot_length/60/2) + seconds // 60])\n",
    "        seconds += slot_length\n",
    "        seconds %= 24 * 60 * 60\n",
    "    simulation_heat_demands.append(demand_series)\n",
    "\n",
    "tasks = [{'chpp_actions': chpp_action_sets[chpp_actions_choices[i]],\n",
    "          'chpp_mode_id': chpp_mode_id_choices[i], \n",
    "          'chpp_staying_time': chpp_staying_time_choices[i], \n",
    "          'hwt_capacity': hwt_capacity,\n",
    "          'hwt_soc': hwt_soc_choices[i],\n",
    "          'hwt_absolute_loss': hwt_absolute_loss,\n",
    "          'hwt_relative_loss': hwt_relative_loss,\n",
    "          'hwt_min_soc': hwt_min_soc_choices[i], \n",
    "          'hwt_max_soc': hwt_max_soc_choices[i], \n",
    "          'simulation_heat_demand': simulation_heat_demands[i], \n",
    "          'series_length': slot_count,\n",
    "          'tick_length': tick_length,\n",
    "          'slot_length': slot_length,\n",
    "          'buffers': buffers,\n",
    "          'confidence': confidence,\n",
    "          'transition': transition,\n",
    "          'estimator_depth': estimator_depth,\n",
    "          'classifier': classifier,\n",
    "          'classifier_depth': classifier_depth,\n",
    "          'state_mapping': state_mapping\n",
    "         } for i in range(simulation_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51329d583df448bb19e0a41aec4b5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# perform evaluation\n",
    "\n",
    "# !!!\n",
    "# Attention: For reproducible results make sure to run the previous code block before running this block\n",
    "# !!!\n",
    "\n",
    "\n",
    "# !!!\n",
    "# Attention: Code is not optimized for multiprocessing! This is faster than using a multiprocessing pool.\n",
    "#\n",
    "# From the pytorch documentation: \"Sharing CUDA tensors between processes is supported only in Python 3, using a spawn or forkserver start methods.\"\n",
    "#\n",
    "# On Unix \"fork\" is standard. Options \"spawn\" and \"forkserver\"  didn't work in jupyter lab.\n",
    "# !!!\n",
    "\n",
    "results = []\n",
    "with tqdm(total=simulation_count) as pbar:\n",
    "    for task in tasks:\n",
    "        results.append(generate_and_evaluate_load_profile(**task))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 520 feasible profiles\n",
      "Slot of infeasibility:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infeasible profile indices:\n",
      "[  0   1   6   7   9  10  11  17  19  21  22  23  24  25  31  32  33  36  40  41  42  43  44  46  47  49  51  52  53  55  56  57  59  62  68  70  71\n",
      "  73  74  78  80  81  82  83  84  85  86  87  88  89  90  93  94  95  96  98  99 102 103 104 106 111 112 113 118 120 123 125 126 127 130 131 132 137\n",
      " 138 141 146 148 153 155 156 157 158 162 163 167 169 170 171 175 176 177 178 179 181 184 188 189 193 195 196 201 203 205 206 208 209 210 212 214 220\n",
      " 221 223 224 225 227 229 230 231 232 235 237 238 239 240 242 243 244 245 247 248 249 250 253 259 273 277 280 283 288 289 290 292 293 295 299 304 310\n",
      " 312 316 317 318 319 322 326 327 328 329 334 335 339 340 344 350 352 353 355 356 358 360 362 364 365 366 370 371 373 375 376 377 382 385 389 396 397\n",
      " 398 399 400 401 402 403 406 408 410 411 413 414 415 416 417 418 421 422 424 425 427 428 429 430 431 435 436 438 439 441 442 443 445 446 447 450 451\n",
      " 452 453 455 457 462 463 464 465 466 467 469 470 472 474 475 476 477 480 481 482 483 486 488 490 497 498 500 501 504 505 506 508 509 512 514 515 516\n",
      " 517 519 520 522 528 534 535 536 540 542 546 548 550 551 553 554 556 563 566 568 569 570 571 572 573 577 583 586 588 591 592 594 596 599 600 601 603\n",
      " 606 609 610 611 614 616 618 620 622 624 625 626 627 631 632 638 639 641 644 646 649 650 652 654 655 657 658 659 661 662 663 665 666 667 668 669 670\n",
      " 673 678 679 683 685 686 687 693 697 698 699 700 702 703 705 706 711 713 715 717 720 721 722 724 726 727 728 729 730 731 734 735 739 740 742 744 746\n",
      " 749 750 754 755 759 762 763 765 768 776 779 782 785 786 787 792 793 794 797 798 801 802 803 804 809 810 813 815 816 817 818 820 821 824 827 831 832\n",
      " 838 842 843 844 847 848 849 855 856 858 859 864 865 867 870 874 877 878 884 885 887 891 893 895 897 900 901 902 904 907 909 910 913 917 918 924 927\n",
      " 928 929 933 937 941 942 945 946 947 948 950 951 952 953 954 955 956 957 958 959 961 964 968 971 973 975 976 978 979 981 982 983 989 991 993 994]\n"
     ]
    }
   ],
   "source": [
    "hist_data = [results[i][0] for i in range(len(results))]\n",
    "print('Generated %d feasible profiles'%sum([i<0 for i in hist_data]))\n",
    "\n",
    "print('Slot of infeasibility:')\n",
    "fig = figure(figsize=(25,7))\n",
    "fig.set_facecolor('white')\n",
    "ax = subplot(121)\n",
    "ax.set_title('Simulation result')\n",
    "ax.hist(hist_data, 97)\n",
    "plt.show()\n",
    "\n",
    "print('Infeasible profile indices:')\n",
    "print(np.array([i for i in range(len(hist_data)) if hist_data[i]>=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffers {'min_staying_time': (0, 0), 'min_charge': 0, 'max_charge': 0}\n",
      "with confidence 0.950000\n",
      "false positives: 1927, 0.010036\n",
      "false negatives: 8250, 0.042969\n",
      "correctly classified: 181823, 0.946995\n"
     ]
    }
   ],
   "source": [
    "print('buffers %s'%str(buffers))\n",
    "print('with confidence %f'%(confidence))\n",
    "\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "total_number = 0\n",
    "\n",
    "for result in results:\n",
    "    simulated_data = []\n",
    "    for i in range(slot_count):\n",
    "        slot_data = np.zeros(len(result[3][0]))\n",
    "        slot_data[result[-1][i][\"feasible_actions\"]] = 1\n",
    "        simulated_data.append(slot_data)\n",
    "    simulated_data = np.array(simulated_data)\n",
    "    difference = (torch.sigmoid(result[3]) >= confidence).data.numpy().round() - simulated_data\n",
    "    false_positives += sum(difference > 0)\n",
    "    false_negatives += sum(difference < 0)\n",
    "    total_number += len(result[3]) * len(result[3][0])\n",
    "\n",
    "print('false positives: %d, %f'%(false_positives, false_positives/total_number))\n",
    "print('false negatives: %d, %f'%(false_negatives, false_negatives/total_number))\n",
    "print('correctly classified: %d, %f'%(total_number-false_positives-false_negatives, (total_number-false_positives-false_negatives)/total_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08b61146bc704167a2c7f9d255930a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of feasible profiles when neglecting min and max SOC of HWT: 953\n"
     ]
    }
   ],
   "source": [
    "# determine feasibility without min and max SOC for the HWT\n",
    "infeasibility_slots = []\n",
    "with tqdm(total=simulation_count) as pbar:\n",
    "    for i, task in enumerate(tasks):\n",
    "        action_history = [record['action_choice'] for record in results[i][-1]][:-1]\n",
    "        infeasibility_slots.append(determine_feasibility_of_load_profile(**dict(**{k:v for k,v in task.items() if k not in ['hwt_min_soc','hwt_max_soc']}, \n",
    "                                                                                hwt_min_soc = 0, \n",
    "                                                                                hwt_max_soc = 1,\n",
    "                                                                                action_history = action_history\n",
    "                                                                               )))\n",
    "        pbar.update(1)\n",
    "                                   \n",
    "print('Number of feasible profiles when neglecting min and max SOC of HWT: %d'%(sum([1 for i in infeasibility_slots if i < 0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation details\n",
    "\n",
    "\n",
    "The following code can be used to look into the details of an individual simulation run. Simply specify the idx at the beginning of the next code block.\n",
    "\n",
    "The plots show the feasibility of actions for each time slot. Dark areas are infeasible actions. Please keep in mind, that the feasibility of actions depends on the state which in turn depends on the load profile, i.e., the performed actions. The respective load profile is plotted in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state\n",
      "{'state': (0.0, 1.0, 0.3125, 0.02, 0.03125, 0.03125, 0.15, 0.75), 'feasible_actions': [1], 'action_choice': 1, 'external_input': 0.0702, 'debugging_info': None}\n",
      "id 13, soc 0.031250, infeasibility @-1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Delta\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1008 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# index of simulation run\n",
    "idx = 13\n",
    "\n",
    "# confidence used for plotting\n",
    "plot_confidence = 0.85\n",
    "\n",
    "# plot design\n",
    "standard_cmap = matplotlib.colors.LinearSegmentedColormap.from_list('standard', ['#663854', '#BEBEBE', '#FAFAD2'])\n",
    "delta_cmap = matplotlib.colors.LinearSegmentedColormap.from_list('delta', ['#6082B6', '#FAFAD2', '#E66771'])\n",
    "\n",
    "# dataset parameters\n",
    "number_of_actions = len(results[idx][3][0])\n",
    "\n",
    "print('Initial state')\n",
    "print(results[idx][-1][0])\n",
    "\n",
    "actions = [results[idx][-1][i][\"action_choice\"] for i in range(slot_count)]\n",
    "\n",
    "generated_data = results[idx][3]\n",
    "simulated_data = []\n",
    "for i in range(slot_count):\n",
    "    slot_data = np.zeros(number_of_actions)\n",
    "    slot_data[results[idx][-1][i][\"feasible_actions\"]] = 1\n",
    "    simulated_data.append(slot_data)\n",
    "simulated_data = np.array(simulated_data)\n",
    "\n",
    "infeasible_at = results[idx][0]\n",
    "print('id %d, soc %f, infeasibility @%d'%(idx, results[idx][-1][0][\"state\"][4], infeasible_at))\n",
    "\n",
    "fig = figure(figsize=(25,7))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "ax = subplot(121)\n",
    "ax.set_title('Generation Output')\n",
    "ax.imshow(torch.sigmoid(generated_data).data.numpy().transpose(), cmap=standard_cmap, origin='lower', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "ax2 = subplot(122)\n",
    "ax2.set_title('Simulated Data')\n",
    "ax2.step(range(0,96), actions, 'r', where='mid')\n",
    "ax2.imshow(simulated_data.transpose(), cmap=standard_cmap, origin='lower', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Generation Delta')\n",
    "fig = figure(figsize=(25,14))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "ax = subplot(121)\n",
    "ax.set_title('Delta, Generation Model >= %f & Real Data'%plot_confidence)\n",
    "ax.imshow((torch.sigmoid(generated_data) >= plot_confidence).data.numpy().round().transpose() - simulated_data.transpose(), cmap=delta_cmap, origin='lower', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.step(range(0,96), actions, 'r', where='mid')\n",
    "\n",
    "ax2 = subplot(122)\n",
    "ax2.set_title('Delta, Generation Model >= %f & Real Data'%confidence)\n",
    "ax2.imshow((torch.sigmoid(generated_data) >= confidence).data.numpy().round().transpose() - simulated_data.transpose(), cmap=delta_cmap, origin='lower', aspect='auto', vmin=-1, vmax=1)\n",
    "ax2.step(range(0,96), actions, 'r', where='mid')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot -1\n",
      "Sim: {'state': (1.0, 0.0, 0.041666666666666664, 0.8705, 0.03125, 0.03125, 0.15, 0.75), 'feasible_actions': None, 'action_choice': None, 'external_input': None, 'debugging_info': None}\n",
      "Gen: [1.    , 0.    , 0.0312, 0.883 , 0.0312, 0.0312, 0.15  , 0.75  ]\n",
      "tensor([0.9902, 0.0098], grad_fn=<SigmoidBackward>)\n",
      "Rating of chosen action: tensor([[0.9902, 0.0098]], grad_fn=<SigmoidBackward>)\n",
      "slot 0\n",
      "Sim: {'state': (0.0, 1.0, 0.3125, 0.02, 0.03125, 0.03125, 0.15, 0.75), 'feasible_actions': [1], 'action_choice': 1, 'external_input': 0.0702, 'debugging_info': None}\n",
      "Gen: [0.    , 1.    , 0.3125, 0.02  , 0.0312, 0.0312, 0.15  , 0.75  ]\n",
      "tensor([0.0096, 0.9900], grad_fn=<SigmoidBackward>)\n",
      "Rating of chosen action: tensor(0.9900, grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "start_slot = infeasible_at\n",
    "end_slot = start_slot + 1\n",
    "\n",
    "#start_slot = 0\n",
    "#end_slot = 10\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for i in range(start_slot, end_slot+1):\n",
    "    print('slot %d'%i)\n",
    "    print('Sim:',end=\" \")\n",
    "    print(results[idx][-1][i])\n",
    "    print('Gen:',end=\" \")\n",
    "    print(np.array2string(np.around(results[idx][2][i],4), separator=', '))\n",
    "    print(torch.sigmoid(results[idx][3][i]))\n",
    "    print('Rating of chosen action:',end=\" \")\n",
    "    print(torch.sigmoid(results[idx][3][i][results[idx][-1][i]['action_choice']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.      1.      0.3125  0.02    0.03125 0.03125 0.15    0.75   ]\n",
      "[-0.000004  1.000005  0.322993  0.096449  0.03125   0.031252  0.150005  0.749993]\n",
      "[0.       1.       0.322917 0.097    0.03125  0.03125  0.15     0.75    ]\n"
     ]
    }
   ],
   "source": [
    "slot = 0\n",
    "\n",
    "input_state = torch.Tensor(results[idx][2][slot]).unsqueeze(0)\n",
    "input_one_hot = torch.zeros(number_of_actions)\n",
    "input_one_hot[results[idx][-1][slot]['action_choice']] = 1\n",
    "input_one_hot = input_one_hot.unsqueeze(0)\n",
    "input_external = torch.Tensor([results[idx][-1][slot]['external_input']]).unsqueeze(0)\n",
    "\n",
    "print(input_state.data.numpy()[0])\n",
    "\n",
    "print(transition(input_state, input_one_hot, input_external, estimator_depth).data.numpy()[0])\n",
    "print(results[idx][2][slot+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
