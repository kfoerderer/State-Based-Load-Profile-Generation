{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for generating Battery load profiles\n",
    "\n",
    "The code is structured as follows:\n",
    "- Imports and definition of some basic parameters\n",
    "- Simulation model for creating the data\n",
    "- Datasets using the simulation models\n",
    "- Shared ANN components\n",
    "- State Estimator definition and Training\n",
    "- Classifier definition and Training\n",
    "- Evaluation\n",
    "- Additional code for displaying individual created load profiles\n",
    "\n",
    "Please note:\n",
    "- The code is set up to use CUDA. Remove the .cuda() calls to run on CPU.\n",
    "- Batches are created in individual processes.\n",
    "- To run the evaluation code make sure to install 'jupyter-widgets/jupyterlab-manager' via the command 'jupyter labextension install @jupyter-widgets/jupyterlab-manager'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "systems_module_location = \"../../simulation\"\n",
    "\n",
    "import logging\n",
    "\n",
    "# add module location to $PATH if it is missing\n",
    "import sys\n",
    "if systems_module_location not in sys.path:\n",
    "    sys.path.append(systems_module_location)\n",
    "\n",
    "import os\n",
    "    \n",
    "import systems\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.multiprocessing import Manager, Process, Queue\n",
    "import queue\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6, suppress=True, linewidth=150)\n",
    "\n",
    "# Length of a tick in seconds\n",
    "tick_length = 15 * 60\n",
    "# number of seconds in a slot\n",
    "slot_length = 15 * 60\n",
    "\n",
    "# number of slots in a load profile\n",
    "slot_count = 4 * 24\n",
    "\n",
    "# number of slots in a day\n",
    "slots_per_day = 24 * 60 * 60 / slot_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator for creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def battery_random_strategy(time, delta_time, action_idxs, battery):\n",
    "    return np.random.choice(action_idxs, 1)[0]\n",
    "\n",
    "class BatterySimulation:\n",
    "\n",
    "    def __init__(self, battery, battery_strategy):\n",
    "        self.battery = battery\n",
    "        self.battery_strategy = battery_strategy\n",
    "        \n",
    "        self.actions = battery.get_actions() # dictionary mapping all combinations of actions\n",
    "        \n",
    "        self.load_profile = []\n",
    "        self.infeasibility_slot = -1        \n",
    "                \n",
    "        self.records = []\n",
    "        \n",
    "        \n",
    "    def add_record(self, feasible_actions, action_choice, external_input, debugging_info):\n",
    "        record = {\n",
    "            # bat_soc\n",
    "            'state' :   (round(self.battery.get_state_of_charge(), 4),),\n",
    "            'feasible_actions' : feasible_actions,\n",
    "            'action_choice' : action_choice,\n",
    "            'external_input' : external_input,\n",
    "            'debugging_info' : debugging_info               \n",
    "        }\n",
    "        self.records.append(record)\n",
    "        \n",
    "    def run(self, tick_length, slot_length, until):\n",
    "        time = 0\n",
    "        sum_of_powers = np.array([0., 0.])\n",
    "        while time < until:\n",
    "        \n",
    "            #\n",
    "            # determine feasible actions\n",
    "            #\n",
    "\n",
    "            # battery\n",
    "            feasible_action_idxs = self.battery.get_feasible_action_idxs(tick_length)\n",
    "\n",
    "            # choose an action\n",
    "            action_choice = self.battery_strategy(time, tick_length, feasible_action_idxs, self.battery)\n",
    "               \n",
    "            self.add_record(feasible_action_idxs, action_choice, 0, None)\n",
    "            \n",
    "            #\n",
    "            # battery simulation step\n",
    "            #            \n",
    "            sum_of_powers[0] += self.battery.state_transition(tick_length, action_choice).el_power\n",
    "            \n",
    "            # evaluate feasibility\n",
    "            if self.infeasibility_slot < 0 and action_choice not in feasible_action_idxs:\n",
    "                self.infeasibility_slot = time // slot_length\n",
    "\n",
    "            # generate new slot\n",
    "            if time % slot_length == slot_length-tick_length:\n",
    "                # reached end of slot\n",
    "                self.load_profile.append(sum_of_powers[0] / (slot_length/tick_length))\n",
    "                # reset sum\n",
    "                sum_of_powers = np.array([0., 0.])\n",
    "            \n",
    "            time += tick_length\n",
    "            \n",
    "        self.add_record(None, None, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets for state transition and classification tasks\n",
    "\n",
    "All datasets are generated on the fly using the simulation model defined above.\n",
    "\n",
    "### Parameters for initializing simulations\n",
    "The following parameters are used to initialize the simulation (and evaluation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "battery_socs = np.linspace(0, 1, 101)\n",
    "\n",
    "battery_charging_efficiency = 0.94\n",
    "battery_discharging_efficiency = 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatteryTransitionDataset(torch.utils.data.Dataset):\n",
    "    '''    \n",
    "    Generates a dataset for state transition learning    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tick_length, slot_length, slot_count, \n",
    "                 battery_socs, battery_charging_efficiency, battery_discharging_efficiency):\n",
    "        self.tick_length = tick_length\n",
    "        self.slot_length = slot_length\n",
    "        self.slot_count = slot_count\n",
    "        \n",
    "        self.battery_socs = battery_socs\n",
    "        self.battery_charging_efficiency = battery_charging_efficiency\n",
    "        self.battery_discharging_efficiency = battery_discharging_efficiency\n",
    "        \n",
    "    def set_slot_count(self, slot_count):\n",
    "        self.slot_count = slot_count\n",
    "        \n",
    "    def index_to_parameter_indices(self, index):\n",
    "        \"\"\"\n",
    "        For on the fly parameter mapping\n",
    "        \"\"\"\n",
    "        \n",
    "        battery_soc = index % len(self.battery_socs)        \n",
    "        return (battery_soc,)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.battery_socs)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #\n",
    "        # map index to parameters\n",
    "        #\n",
    "        indices = self.index_to_parameter_indices(index)\n",
    "        \n",
    "        battery_soc = round(self.battery_socs[indices[0]], 4)\n",
    "        \n",
    "        #\n",
    "        # initialize systems\n",
    "        #\n",
    "        battery = systems.Battery(1, 1, 100, battery_soc, self.battery_charging_efficiency, self.battery_discharging_efficiency, 0, 0)\n",
    "        \n",
    "        # run simulation to advance states\n",
    "        simulation = BatterySimulation(battery, battery_random_strategy)\n",
    "        simulation.run(self.tick_length, self.slot_length, self.slot_count * self.slot_length)\n",
    "        \n",
    "        input_one_hot = [] # don't start with [0,0] for this recurrent network with readable states\n",
    "        for record in simulation.records:\n",
    "            #print(record)\n",
    "            if record['action_choice'] != None:\n",
    "                one_hot = np.zeros(len(simulation.actions))\n",
    "                one_hot[record['action_choice']] = 1\n",
    "                input_one_hot.append(one_hot)\n",
    "        \n",
    "        return {'input_state': torch.Tensor(simulation.records[0]['state']),\n",
    "                'input_one_hot': torch.Tensor(input_one_hot),\n",
    "                'input_external': torch.zeros(self.slot_count).view(-1,1),\n",
    "                'output_states': torch.Tensor([simulation.records[i+1]['state'] for i in range(self.slot_count)])\n",
    "               }\n",
    "    \n",
    "transition_dataset = BatteryTransitionDataset(tick_length, slot_length, 1, battery_socs, battery_charging_efficiency, battery_discharging_efficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatteryClassificationDataset(torch.utils.data.Dataset):\n",
    "    '''    \n",
    "    Generates a dataset for classification learning    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tick_length, slot_length, battery_socs, battery_charging_efficiency, battery_discharging_efficiency):        \n",
    "        self.tick_length = tick_length\n",
    "        self.slot_length = slot_length\n",
    "        \n",
    "        self.battery_socs = battery_socs\n",
    "        self.battery_charging_efficiency = battery_charging_efficiency\n",
    "        self.battery_discharging_efficiency = battery_discharging_efficiency\n",
    "        \n",
    "        #self.weighted_soc_idxs = []\n",
    "        #for i, soc in enumerate(self.battery_socs):\n",
    "        #    if soc <= 0.3 or soc >= 0.75:\n",
    "        #        self.weighted_soc_idxs.append(i)\n",
    "        #    self.weighted_soc_idxs.append(i)\n",
    "\n",
    "    def sample_index(self):\n",
    "        ''' Randomly samples an index for batch creation '''\n",
    "\n",
    "        return np.random.randint(len(self.battery_socs)) #np.random.choice(self.weighted_soc_idxs, 1)[0]\n",
    "                \n",
    "        \n",
    "    def set_slot_count(self, slot_count):\n",
    "        self.slot_count = slot_count\n",
    "        \n",
    "        \n",
    "    def index_to_parameter_indices(self, index):\n",
    "        \"\"\"\n",
    "        For on the fly parameter mapping\n",
    "        index -> indices-tuple (0: battery_soc)\n",
    "        \"\"\"\n",
    "        \n",
    "        battery_soc = index % len(self.battery_socs)        \n",
    "        \n",
    "        return (battery_soc,)\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.battery_socs)\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #\n",
    "        # map index to parameters\n",
    "        #\n",
    "        indices = self.index_to_parameter_indices(index)\n",
    "        \n",
    "        battery_soc = round(self.battery_socs[indices[0]], 4)\n",
    "        \n",
    "        #\n",
    "        # initialize systems\n",
    "        #\n",
    "        battery = systems.Battery(1, 1, 100, battery_soc, self.battery_charging_efficiency, self.battery_discharging_efficiency, 0, 0)\n",
    "        \n",
    "        # run simulation to advance states\n",
    "        simulation = BatterySimulation(battery, battery_random_strategy)\n",
    "        simulation.run(self.tick_length, self.slot_length, self.slot_length)\n",
    "        \n",
    "        feasible_actions_one_hot = np.zeros(len(simulation.actions))\n",
    "        feasible_actions_one_hot[simulation.records[0]['feasible_actions']] = 1\n",
    "        \n",
    "        return {'input_state': torch.Tensor(simulation.records[0]['state']), \n",
    "                'output': torch.Tensor(feasible_actions_one_hot)}\n",
    "    \n",
    "classification_dataset = BatteryClassificationDataset(tick_length, slot_length, battery_socs, battery_charging_efficiency, battery_discharging_efficiency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared ANN Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size, output_size = size, size\n",
    "        \n",
    "        self.result_linear = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.result_activation = nn.Tanh()\n",
    "        self.gate_linear = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.gate_activation = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        result = self.result_linear(input_tensor)\n",
    "        result = self.result_activation(result)\n",
    "        gate = self.gate_linear(input_tensor)\n",
    "        gate = self.gate_activation(gate)\n",
    "        \n",
    "        return result * gate\n",
    "        \n",
    "class GatedResidualLinearBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, internal_size, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size, output_size = size, size\n",
    "        \n",
    "        self.result_linear0 = nn.Linear(input_size, internal_size, bias=bias)\n",
    "        self.result_activation0 = nn.Tanh()\n",
    "        self.result_linear1 = nn.Linear(internal_size, internal_size, bias=bias)\n",
    "        self.result_activation1 = nn.Tanh()\n",
    "        self.result_linear2 = nn.Linear(internal_size, output_size, bias=bias)\n",
    "        \n",
    "        self.gate_linear0 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.gate_activation0 = nn.Tanh()\n",
    "        self.gate_linear1 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.gate_activation1 = nn.Tanh()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        result = self.result_linear0(input_tensor)\n",
    "        result = self.result_activation0(result)\n",
    "        result = self.result_linear1(result)\n",
    "        result = self.result_activation1(result)\n",
    "        result = self.result_linear2(result)\n",
    "        \n",
    "        gate = self.gate_linear0(input_tensor)\n",
    "        gate = self.gate_activation0(gate)\n",
    "        gate = self.gate_linear1(gate)\n",
    "        gate = self.gate_activation1(gate)\n",
    "        \n",
    "        return result * gate + input_tensor\n",
    "    \n",
    "class LinearBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, size, bias=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size, output_size = size, size\n",
    "        \n",
    "        self.layer_0 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.layer_0_activation = nn.ReLU()\n",
    "        self.layer_1 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.layer_1_activation = nn.ReLU()\n",
    "        self.layer_2 = nn.Linear(input_size, output_size, bias=bias)\n",
    "        self.layer_2_activation = nn.ReLU()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        \n",
    "        result = self.layer_0(input_tensor)\n",
    "        result = self.layer_0_activation(result)\n",
    "        result = self.layer_1(result)\n",
    "        result = self.layer_1_activation(result)\n",
    "        result = self.layer_2(result)\n",
    "        result = self.layer_2_activation(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.uniform_(m.weight, -1, 1)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTransition(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, network_width, state_size):\n",
    "        super().__init__() \n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.input_size = input_size\n",
    "        self.network_width = network_width\n",
    "        \n",
    "        self.tr0 = nn.Linear(input_size, network_width, bias=True)\n",
    "        self.tr1 = LinearBlock(network_width, True)\n",
    "        self.tr1g = LinearBlock(network_width, True)\n",
    "        self.tr2 = LinearBlock(network_width, True)\n",
    "        self.tr2g = LinearBlock(network_width, True)\n",
    "        self.tr3 = LinearBlock(network_width, True)\n",
    "        self.tr3g = LinearBlock(network_width, True)\n",
    "        self.tr4 = LinearBlock(network_width, True)\n",
    "        self.tr4g = LinearBlock(network_width, True)\n",
    "        self.tr5 = LinearBlock(network_width, True)\n",
    "        self.tr5g = LinearBlock(network_width, True)\n",
    "        self.tr6 = nn.Linear(network_width, state_size, bias=True)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_state, input_one_hot, input_external, depth=sys.maxsize):\n",
    "                    \n",
    "        input_tensor = torch.cat((input_state, input_one_hot, input_external), dim=1)\n",
    "        \n",
    "        #print(input_tensor.size())\n",
    "        \n",
    "        state = self.tr0(input_tensor)\n",
    "        if depth > 0:\n",
    "                state = self.tr1(state) * self.tr1g(state) + state\n",
    "        if depth > 1:\n",
    "                state = self.tr2(state) * self.tr2g(state) + state\n",
    "        if depth > 2:\n",
    "                state = self.tr3(state) * self.tr3g(state) + state\n",
    "        if depth > 3:\n",
    "                state = self.tr4(state) * self.tr4g(state) + state\n",
    "        if depth > 4:\n",
    "                state = self.tr5(state) * self.tr5g(state) + state      \n",
    "                \n",
    "        state = self.tr6(state) + input_state\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def initialize_block_weigths(self, block, init_function):\n",
    "        if block == 1:\n",
    "            self.tr1.apply(init_function)\n",
    "            self.tr1g.apply(init_function)\n",
    "        elif block == 2:\n",
    "            self.tr2.apply(init_function)\n",
    "            self.tr2g.apply(init_function)\n",
    "        elif block == 3:\n",
    "            self.tr3.apply(init_function)\n",
    "            self.tr3g.apply(init_function)\n",
    "        elif block == 4:\n",
    "            self.tr4.apply(init_function)\n",
    "            self.tr4g.apply(init_function)\n",
    "        elif block == 5:\n",
    "            self.tr5.apply(init_function)\n",
    "            self.tr5g.apply(init_function)\n",
    "\n",
    "#transition.apply(init_weights) <- problems with NaNs, maybe caused by MSELoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_batch_processes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_batch(batch_queue, batch_size, input_queue, transition_dataset):\n",
    "    ''' Function used by process to create batches. Batches are created according to the parameters \n",
    "    given in the input_queue which specifies the number of unfolding steps. '''\n",
    "    while True:\n",
    "        # set the number of unfolding steps used for creating the next batch      \n",
    "        transition_dataset.set_slot_count(input_queue.get())\n",
    "        \n",
    "        # draw initial states\n",
    "        indices = np.random.randint(len(transition_dataset), size=(batch_size), dtype='int64')\n",
    "        \n",
    "        # create batch\n",
    "        batch = {}\n",
    "        for idx in indices:    \n",
    "            for key, value in transition_dataset[idx].items():\n",
    "                if key in batch:\n",
    "                    batch[key] = torch.cat([batch[key], value.unsqueeze(0)], dim=0)\n",
    "                else:\n",
    "                    batch[key] = value.unsqueeze(0)\n",
    "        batch_queue.put(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "transition_loss_function = nn.MSELoss().cuda()\n",
    "target_function_weights = torch.Tensor([20,1,1,20,80,10,10,1,1]).cuda()\n",
    "\n",
    "# training parameters\n",
    "batch_size=32\n",
    "training_batch_count = 150001\n",
    "training_summary_at = 1000\n",
    "\n",
    "# evaluation\n",
    "evaluation_at = 10000\n",
    "evaluation_batch_count = 1000\n",
    "evaluation_on_low_training_loss = True\n",
    "best_model_loss = 0.1\n",
    "\n",
    "# regularization\n",
    "l1_crit = nn.L1Loss(reduction='sum').cuda()\n",
    "reg_loss_factor = 1/100000000 #1/10000000\n",
    "\n",
    "# learning rate adaptation\n",
    "learning_rate_initialization = 1e-3\n",
    "learning_rate_loss_factor = 1/1#0#00000\n",
    "learning_rate_decay_after = 50000\n",
    "learning_rate_decay_at = 10000\n",
    "learning_rate_decay_factor = 1/2\n",
    "\n",
    "# modell unfolding\n",
    "unfolding_after = 1000\n",
    "unfolding_at = 1000\n",
    "unfolding_delta = 1\n",
    "unfolding_share = 0\n",
    "unfolding_max_steps = 4\n",
    "single_step_share = 1\n",
    "unfolding_share = unfolding_share / (unfolding_share + single_step_share)\n",
    "\n",
    "# pretraining\n",
    "use_pretraining = False\n",
    "pretraining_initial_depth = 1\n",
    "pretraining_max_depth = 3\n",
    "pretraining_expand_depth_at = 30000\n",
    "\n",
    "# model parameters\n",
    "model_input_size = 1 + 1 + 201 \n",
    "model_width = 64\n",
    "model_output_size = 1\n",
    "model_depth = 2 # pretrain overrides this parameter\n",
    "\n",
    "#\n",
    "# set up\n",
    "#\n",
    "training_run = str(int(time.time()))\n",
    "training_out = \"transition/\" + training_run\n",
    "\n",
    "# create output directory\n",
    "if not os.path.exists(training_out):\n",
    "    os.makedirs(training_out)\n",
    "\n",
    "# set up logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/info.log\".format(training_out)),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "\n",
    "logging.info(\"batch_size: %d\"%batch_size)\n",
    "logging.info(\"learning_rate_initialization: %f, learning_rate_loss_factor: %f, learning_rate_decay_after: %d, learning_rate_decay_at: %d, learning_rate_decay_factor: %f\"%\n",
    "            (learning_rate_initialization, learning_rate_loss_factor, learning_rate_decay_after, learning_rate_decay_at, learning_rate_decay_factor))\n",
    "logging.info('weigths: %s'%str(target_function_weights))\n",
    "logging.info('regularization factor: %.16f'%reg_loss_factor)\n",
    "logging.info(\"unfolding_after: %d, unfolding_at: %d, unfolding_delta: %d, unfolding_share: %f\"%(unfolding_after, unfolding_at, unfolding_delta, unfolding_share))\n",
    "\n",
    "for model_number in range(10):\n",
    "\n",
    "    learning_rate = learning_rate_initialization\n",
    "    \n",
    "    # queue holding batches\n",
    "    multiprocessing_manager = Manager()\n",
    "    transition_batch_queue = multiprocessing_manager.Queue(10)\n",
    "    transition_input_queue = multiprocessing_manager.Queue(20)\n",
    "\n",
    "    # stop the batch creating process if it is already running\n",
    "    for process in transition_batch_processes:\n",
    "        process.terminate()\n",
    "        process.join() # kill zombie process\n",
    "\n",
    "    # start batch creating processes\n",
    "    for i in range(4):\n",
    "        process = Process(target=create_transition_batch, \n",
    "                          args=(transition_batch_queue, batch_size, transition_input_queue, transition_dataset))\n",
    "        process.start()\n",
    "        transition_batch_processes.append(process)\n",
    "\n",
    "\n",
    "    transition = StateTransition(model_input_size, model_width, model_output_size).cuda()\n",
    "    logging.info('---------------------------------')\n",
    "    if use_pretraining:\n",
    "        estimator_depth = pretraining_initial_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d to %d, step at %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          pretraining_initial_depth, pretraining_max_depth, pretraining_expand_depth_at))\n",
    "    \n",
    "    else:\n",
    "        estimator_depth = model_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          estimator_depth))\n",
    "    \n",
    "    transition_solver = optim.Adam(transition.parameters(), lr=5e-3)\n",
    "\n",
    "    worst_loss = -1\n",
    "    worst_loss_unfolding = -1\n",
    "    worst_est = None\n",
    "    worst_target = None\n",
    "    \n",
    "    unfolding_limit= 2\n",
    "    n_unfolding = 0\n",
    "    n_single_step = 0    \n",
    "\n",
    "    force_evaluation = False\n",
    "    for batch_number in range(training_batch_count):\n",
    "\n",
    "        # create input for the batch generation process\n",
    "        try:\n",
    "            while transition_input_queue.full() == False:\n",
    "                # determine number of steps\n",
    "                if batch_number > unfolding_after and np.random.random() < unfolding_share:\n",
    "                    number_training_steps = unfolding_limit + 1 #np.random.randint(2, unfolding_limit+1)\n",
    "                else:\n",
    "                    number_training_steps = 1\n",
    "                transition_input_queue.put_nowait(number_training_steps)\n",
    "        except queue.Full:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            batch = transition_batch_queue.get()\n",
    "        except FileNotFoundError:\n",
    "            batch = transition_batch_queue.get()\n",
    "\n",
    "        state = batch['input_state'].cuda()\n",
    "        batch['input_one_hot'] = batch['input_one_hot'].cuda()\n",
    "        batch['input_external'] = batch['input_external'].cuda()\n",
    "\n",
    "        \n",
    "        transition_loss = torch.zeros(1).cuda()\n",
    "        successful_iterations = 0\n",
    "        for i in range(min(unfolding_limit, batch['input_one_hot'].size(1))):\n",
    "            new_state = transition(state, \n",
    "                                   batch['input_one_hot'][:,i], \n",
    "                                   batch['input_external'][:,i].view(-1,1), \n",
    "                                   estimator_depth)\n",
    "\n",
    "            if torch.isnan(new_state).any():\n",
    "                logging.warning('NaN')\n",
    "                unfolding_limit = max(unfolding_limit - unfolding_delta, 2)\n",
    "                break        \n",
    "\n",
    "            state = new_state\n",
    "            target = batch['output_states'][:,i].cuda()\n",
    "            successful_iterations = i + 1\n",
    "            \n",
    "            transition_loss += transition_loss_function(state * target_function_weights, \n",
    "                                                   target * target_function_weights)\n",
    "\n",
    "        if successful_iterations > 1:\n",
    "            n_unfolding += 1\n",
    "        else:\n",
    "            n_single_step += 1\n",
    "            \n",
    "        transition_loss /= successful_iterations\n",
    "        \n",
    "        est = state                \n",
    "        #transition_loss += transition_loss_function(est * target_function_weights, \n",
    "        #                                           target * target_function_weights)\n",
    "\n",
    "        # regularization\n",
    "        reg_loss = torch.zeros(1).cuda()\n",
    "        for param in transition.parameters():\n",
    "            reg_loss += l1_crit(param, torch.zeros(param.size()).cuda())\n",
    "        transition_loss =  transition_loss + reg_loss * reg_loss_factor\n",
    "\n",
    "        if transition_loss.data > worst_loss:\n",
    "            worst_loss = transition_loss.data\n",
    "            worst_loss_unfolding = batch['input_one_hot'].size(1)-1\n",
    "            worst_est = est\n",
    "            worst_target = target\n",
    "\n",
    "        # training step\n",
    "        transition_solver.zero_grad()\n",
    "        transition_loss.backward(retain_graph=True)    \n",
    "        \n",
    "        # compute sum of gradient norms for summary\n",
    "        grad_norm_sum = 0\n",
    "        if batch_number % training_summary_at == 0:            \n",
    "            for p in transition.parameters():\n",
    "                grad_norm_sum += torch.norm(p.grad.data)\n",
    "\n",
    "        # clip grad norms\n",
    "        nn.utils.clip_grad_norm_(transition.parameters(), 0.1)\n",
    "        transition_solver.step()\n",
    "    \n",
    "        # show training progress\n",
    "        if batch_number % training_summary_at == 0 and batch_number > 0:\n",
    "            \n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Summary:')\n",
    "            logging.info('Batch %d, worst loss %f of %d batches (incl. reg.) (unfolding: %d), learning rate %f @est.-depth %d'%\n",
    "                         (batch_number, worst_loss, training_summary_at, worst_loss_unfolding, learning_rate, estimator_depth))\n",
    "            \n",
    "            logging.info(\"Regularization: %f * %.10f = %.10f loss\"%(reg_loss, reg_loss_factor, reg_loss * reg_loss_factor))\n",
    "            logging.info('unfolding %d, single step %d'%(n_unfolding, n_single_step))\n",
    "\n",
    "            if (reg_loss * reg_loss_factor).data * 10 > worst_loss:                \n",
    "                logging.info('reducing reg_loss_factor')\n",
    "                reg_loss_factor *= 0.1\n",
    "                \n",
    "            logging.info('Sum of grad norms of most recent batch: %f'%grad_norm_sum)\n",
    "                                \n",
    "            # do learn rate adaption\n",
    "            learning_rate = min(learning_rate_initialization, max(1e-16, min(float(worst_loss)*learning_rate_loss_factor, learning_rate)))\n",
    "            for param_group in transition_solver.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "            \n",
    "            if worst_loss < best_model_loss:\n",
    "                force_evaluation = evaluation_on_low_training_loss\n",
    "            \n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')\n",
    "            \n",
    "        # conduct model evaluation    \n",
    "        if force_evaluation or (batch_number % evaluation_at == 0 and batch_number > 0):\n",
    "            force_evaluation = False            \n",
    "\n",
    "            # do evaluation\n",
    "            transition.eval()\n",
    "\n",
    "            for evaluation_batch_number in range(evaluation_batch_count):\n",
    "                \n",
    "                # create input for the batch generation process\n",
    "                try:\n",
    "                    while transition_input_queue.full() == False:\n",
    "                        number_training_steps = 1    \n",
    "                        transition_input_queue.put_nowait(number_training_steps)\n",
    "                except queue.Full:\n",
    "                    pass\n",
    "\n",
    "                try:\n",
    "                    batch = transition_batch_queue.get()\n",
    "                except FileNotFoundError:\n",
    "                    batch = transition_batch_queue.get()\n",
    "                \n",
    "                state = batch['input_state'].cuda()\n",
    "                batch['input_one_hot'] = batch['input_one_hot'].cuda()\n",
    "                batch['input_external'] = batch['input_external'].cuda()\n",
    "                \n",
    "                est = transition(state, \n",
    "                                   batch['input_one_hot'][:,0], \n",
    "                                   batch['input_external'][:,0].view(-1,1), \n",
    "                                   estimator_depth)\n",
    "                target = batch['output_states'][:,0].cuda()\n",
    "                transition_loss = transition_loss_function(est * target_function_weights, \n",
    "                                                           target * target_function_weights)\n",
    "\n",
    "                if transition_loss.data > worst_loss:\n",
    "                    worst_loss = transition_loss.data\n",
    "                    worst_est = est\n",
    "                    worst_target = target\n",
    "\n",
    "            # finished\n",
    "            transition.train()\n",
    "\n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Evaluation:')\n",
    "            logging.info('Batch %d, worst loss %f of %d batches (without reg.) @est.-depth %d'%\n",
    "                 (batch_number, worst_loss, evaluation_batch_count, estimator_depth))\n",
    "\n",
    "            if worst_loss < best_model_loss and batch_number > 1:                \n",
    "                best_model_loss = worst_loss\n",
    "                # save modell\n",
    "                file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + \\\n",
    "                            '_transition_' + str(batch_number) + '.pth'\n",
    "                logging.info(\"New best loss %f, saved to file %s\"%(worst_loss,file_name))\n",
    "                torch.save(transition.state_dict(), file_name)\n",
    "\n",
    "                logging.info('Target')\n",
    "                logging.info(worst_target.cpu().numpy())\n",
    "                logging.info('Estimator output')\n",
    "                logging.info(worst_est.detach().cpu().numpy())\n",
    "\n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')    \n",
    "        \n",
    "        # expand model depth when pretraining \n",
    "        if use_pretraining and batch_number > 0 and batch_number % pretraining_expand_depth_at == 0:\n",
    "            if estimator_depth < pretraining_max_depth:\n",
    "                estimator_depth += 1\n",
    "                transition.initialize_block_weigths(estimator_depth, init_weights)\n",
    "        \n",
    "        # adapt learning rate            \n",
    "        if batch_number > learning_rate_decay_after and batch_number % learning_rate_decay_at == 0:\n",
    "            learning_rate = learning_rate * learning_rate_decay_factor\n",
    "            \n",
    "        # adapt unfolding\n",
    "        if batch_number > unfolding_after and batch_number % unfolding_at == 0:\n",
    "            unfolding_limit = min(unfolding_limit + unfolding_delta, min(unfolding_max_steps, slot_count-1))\n",
    "            \n",
    "    # finished training\n",
    "    file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + '_transition_final.pth'\n",
    "    logging.info(\"Finished training, saved to file %s\"%(file_name))\n",
    "    torch.save(transition.state_dict(), file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, state_size, network_width, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.network_width = network_width\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.cl0 = nn.Linear(state_size, network_width)\n",
    "        self.cl1 = LinearBlock(network_width, bias=True)\n",
    "        self.cl2 = LinearBlock(network_width, bias=True)\n",
    "        self.cl3 = LinearBlock(network_width, bias=True)\n",
    "        self.cl4 = LinearBlock(network_width, bias=True)\n",
    "        self.cl5 = LinearBlock(network_width, bias=True)\n",
    "        \n",
    "        self.clbn0 = nn.BatchNorm1d(network_width)\n",
    "        self.clbn1 = nn.BatchNorm1d(network_width)\n",
    "        \n",
    "        self.cl0o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl1o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl2o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl3o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl4o = nn.Linear(network_width, output_size, bias=True)\n",
    "        self.cl5o = nn.Linear(network_width, output_size, bias=True)\n",
    "             \n",
    "        \n",
    "    def forward(self, input_state, depth=sys.maxsize):\n",
    "        #input_power = input_power.unsqueeze(1)\n",
    "         \n",
    "        out = self.cl0(input_state)\n",
    "        #out = self.cl0a(out)\n",
    "        if depth > 0:\n",
    "            out = self.cl1(out)\n",
    "        if depth > 1:\n",
    "            out = self.cl2(out)\n",
    "        if depth > 2:\n",
    "            out = self.cl3(out)\n",
    "        if depth > 3:\n",
    "            out = self.cl4(out)\n",
    "        if depth > 4:\n",
    "            out = self.cl5(out)\n",
    "            \n",
    "            \n",
    "        if depth == 0:\n",
    "            out = self.cl0o(out)\n",
    "        elif depth == 1:\n",
    "            out = self.cl1o(out)\n",
    "        elif depth == 2:\n",
    "            out = self.cl2o(out)\n",
    "        elif depth == 3:\n",
    "            out = self.cl3o(out)\n",
    "        elif depth == 4:\n",
    "            out = self.cl4o(out)\n",
    "        else:\n",
    "            out = self.cl5o(out)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def initialize_block_weigths(self, block, init_function):\n",
    "        if block == 1:\n",
    "            self.cl1.apply(init_function)\n",
    "            self.cl1o.apply(init_function)\n",
    "        elif block == 2:\n",
    "            self.cl2.apply(init_function)\n",
    "            self.cl2o.apply(init_function)\n",
    "        elif block == 3:\n",
    "            self.cl3.apply(init_function)\n",
    "            self.cl3o.apply(init_function)\n",
    "        elif block == 4:\n",
    "            self.cl4.apply(init_function)\n",
    "            self.cl4o.apply(init_function)\n",
    "        elif block == 5:\n",
    "            self.cl5.apply(init_function)\n",
    "            self.cl5o.apply(init_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_batch_processes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classification_batch(batch_queue, batch_size, classification_dataset):\n",
    "    ''' Function used by process to create batches '''\n",
    "    while True:\n",
    "        # draw initial states\n",
    "        indices = [classification_dataset.sample_index() for i in range(batch_size)]\n",
    "        \n",
    "        # create batch\n",
    "        batch = {}\n",
    "        for idx in indices:    \n",
    "            for key, value in classification_dataset[idx].items():\n",
    "                if key in batch:\n",
    "                    batch[key] = torch.cat([batch[key], value.unsqueeze(0)], dim=0)\n",
    "                else:\n",
    "                    batch[key] = value.unsqueeze(0)\n",
    "        batch_queue.put(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "classifier_loss_function = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([1]*201)).cuda() #nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "#training parameters\n",
    "batch_size=32\n",
    "training_batch_count = 250001 #100001\n",
    "training_summary_at = 1000\n",
    "\n",
    "# regularization\n",
    "l1_crit = nn.L1Loss(reduction='sum').cuda()\n",
    "reg_loss_factor = 1/1000 #1/10000\n",
    "\n",
    "# evaluation\n",
    "evaluation_at = 10000\n",
    "evaluation_batch_count = 1000\n",
    "evaluation_on_low_training_loss = True\n",
    "\n",
    "# learning rate adaptation\n",
    "learning_rate_initialization = 5e-3\n",
    "learning_rate_loss_factor = 1/100#00000\n",
    "learning_rate_decay_after = 30000\n",
    "learning_rate_decay_at = 10000\n",
    "learning_rate_decay_factor = 1/2\n",
    "\n",
    "# pretraining\n",
    "use_pretraining = False\n",
    "pretraining_initial_depth = 1\n",
    "pretraining_max_depth = 2\n",
    "pretraining_expand_depth_at = 30000\n",
    "\n",
    "# model parameters\n",
    "model_input_size = 1\n",
    "model_width = 64\n",
    "model_output_size = 201\n",
    "model_depth = 1 # pretraining overrides this parameter\n",
    "\n",
    "best_model_loss = 0.06\n",
    "\n",
    "#\n",
    "# set  up\n",
    "#\n",
    "training_run = str(int(time.time()))\n",
    "training_out = \"classifier/\" + training_run\n",
    "\n",
    "# create output directory\n",
    "if not os.path.exists(training_out):\n",
    "    os.makedirs(training_out)\n",
    "\n",
    "# set up logger\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "    \n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"{0}/info.log\".format(training_out)),\n",
    "        logging.StreamHandler()\n",
    "    ])\n",
    "\n",
    "logging.info(\"learning_rate_initialization: %f, learning_rate_loss_factor: %f, learning_rate_decay_after: %d, learning_rate_decay_at: %d, learning_rate_decay_factor: %f\"%\n",
    "            (learning_rate_initialization, learning_rate_loss_factor, learning_rate_decay_after, learning_rate_decay_at, learning_rate_decay_factor))\n",
    "logging.info('regularization factor: %.10f'%reg_loss_factor)\n",
    "\n",
    "for model_number in range(10):\n",
    "    \n",
    "    learning_rate = learning_rate_initialization\n",
    "    \n",
    "    # queue holding batches\n",
    "    multiprocessing_manager = Manager()\n",
    "    classification_batch_queue = multiprocessing_manager.Queue(10)\n",
    "\n",
    "     # stop the batch creating process if it is already running\n",
    "    for process in classification_batch_processes:\n",
    "        process.terminate()\n",
    "        process.join() # kill zombie process\n",
    "\n",
    "    # start batch creating processes\n",
    "    for i in range(4):\n",
    "        process = Process(target=create_classification_batch, \n",
    "                          args=(classification_batch_queue, batch_size, classification_dataset))\n",
    "        process.start()\n",
    "        classification_batch_processes.append(process)\n",
    "\n",
    "    \n",
    "    classifier = Classifier(model_input_size, model_width, model_output_size).cuda()\n",
    "    classifier.apply(init_weights)\n",
    "    logging.info('---------------------------------')\n",
    "    if use_pretraining:    \n",
    "        classifier_depth = pretraining_initial_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d to %d, step at %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          pretraining_initial_depth, pretraining_max_depth, pretraining_expand_depth_at))\n",
    "    \n",
    "    else:\n",
    "        classifier_depth = model_depth\n",
    "        logging.info(\"Training model #%d: (%d, %d, %d) @ %d\"%(model_number, model_input_size, \n",
    "                                                          model_width, model_output_size,\n",
    "                                                          classifier_depth))\n",
    "    \n",
    "    classifier_solver = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "    \n",
    "    worst_loss = -1\n",
    "    worst_est = None\n",
    "    worst_target = None\n",
    "\n",
    "    force_evaluation = False\n",
    "    for batch_number in range(training_batch_count):\n",
    "        \n",
    "        batch = classification_batch_queue.get()\n",
    "        \n",
    "        input_state = batch['input_state'].cuda()\n",
    "        out = classifier(input_state, classifier_depth)\n",
    "\n",
    "        target = batch['output'].cuda()\n",
    "        \n",
    "        # {0,1} -> {0.01. 0.99}\n",
    "        target = (target * 49 + 0.5) / 50 # 9 ... / 10 for {0.05, 0.95}\n",
    "        \n",
    "        classifier_loss = classifier_loss_function(out, target)\n",
    "        \n",
    "        reg_loss = 0\n",
    "        for param in classifier.parameters():\n",
    "            reg_loss += l1_crit(param, torch.zeros(param.size()).cuda())\n",
    "            \n",
    "        classifier_loss += reg_loss * reg_loss_factor\n",
    "            \n",
    "        if classifier_loss.data > worst_loss:\n",
    "            worst_loss = classifier_loss.data\n",
    "            worst_est = out\n",
    "            worst_target = target\n",
    "\n",
    "        classifier_solver.zero_grad()\n",
    "        classifier_loss.backward(retain_graph=True)    \n",
    "        \n",
    "        \n",
    "        # compute sum of gradient norms for summary\n",
    "        grad_norm_sum = 0\n",
    "        if batch_number % training_summary_at == 0:            \n",
    "            for p in classifier.parameters():\n",
    "                grad_norm_sum += torch.norm(p.grad.data)\n",
    "                \n",
    "        nn.utils.clip_grad_norm_(classifier.parameters(), 0.1)\n",
    "        classifier_solver.step()\n",
    "            \n",
    "        # show training progress\n",
    "        if batch_number % training_summary_at == 0 and batch_number > 0:\n",
    "            \n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Summary:')\n",
    "            logging.info('Batch %d, worst loss %f (incl. reg.) of %d batches, learning rate %f @cl.-depth %d'%\n",
    "                         (batch_number, worst_loss, training_summary_at, learning_rate, classifier_depth))\n",
    "            \n",
    "            logging.info(\"Regularization: %f * %.10f = %.10f\"%(reg_loss, reg_loss_factor, reg_loss * reg_loss_factor))\n",
    "            \n",
    "            if (reg_loss * reg_loss_factor).data * 10 > worst_loss:\n",
    "                logging.info('reducing reg_loss_factor')\n",
    "                reg_loss_factor *= 0.1\n",
    "                \n",
    "            logging.info('Sum of grad norms: %f'%grad_norm_sum)\n",
    "                            \n",
    "            # do learn rate adaption\n",
    "            learning_rate = min(learning_rate_initialization, max(1e-16, min(worst_loss*learning_rate_loss_factor, learning_rate)))\n",
    "            for param_group in classifier_solver.param_groups:\n",
    "                param_group['lr'] = learning_rate\n",
    "            \n",
    "            if worst_loss < best_model_loss:\n",
    "                force_evaluation = evaluation_on_low_training_loss\n",
    "            \n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')\n",
    "            \n",
    "        # conduct model evaluation    \n",
    "        if force_evaluation or (batch_number % evaluation_at == 0 and batch_number > 0):\n",
    "            force_evaluation = False\n",
    "\n",
    "            # do evaluation\n",
    "            classifier.eval()\n",
    "\n",
    "            for evaluation_batch_number in range(evaluation_batch_count):\n",
    "                batch = classification_batch_queue.get()\n",
    "\n",
    "                input_state = batch['input_state'].cuda()\n",
    "                out = classifier(input_state, classifier_depth)\n",
    "                target = batch['output'].cuda()\n",
    "                \n",
    "                # {0,1} -> {0.01. 0.99}\n",
    "                target = (target * 49 + 0.5) / 50 # 9 ... / 10 for {0.05, 0.95}\n",
    "                \n",
    "                classifier_loss = classifier_loss_function(out, target)\n",
    "\n",
    "                if classifier_loss.data > worst_loss:\n",
    "                    worst_loss = classifier_loss.data\n",
    "                    worst_est = out\n",
    "                    worst_target = target\n",
    "\n",
    "            # finished\n",
    "            classifier.train()\n",
    "\n",
    "            logging.info('---------------------------------')\n",
    "            logging.info('Evaluation:')\n",
    "            logging.info('Batch %d, worst loss %f (without reg.) of %d batches @cl.-depth %d'%\n",
    "                 (batch_number, worst_loss, evaluation_batch_count, classifier_depth))\n",
    "\n",
    "            if worst_loss < best_model_loss and batch_number > 0:                \n",
    "                best_model_loss = worst_loss\n",
    "                # save modell\n",
    "                file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + \\\n",
    "                            '_classifier_' + str(batch_number) + '.pth'\n",
    "                logging.info(\"New best loss %f, saved to file %s\"%(worst_loss,file_name))\n",
    "                torch.save(classifier.state_dict(), file_name)\n",
    "\n",
    "                logging.info('Target')\n",
    "                logging.info(worst_target.cpu().numpy())\n",
    "                logging.info('Classifier output')\n",
    "                logging.info(torch.sigmoid(worst_est.detach()).cpu().numpy())\n",
    "\n",
    "            worst_loss = -1\n",
    "            logging.info('---------------------------------')                    \n",
    "        \n",
    "        # expand model depth when pretraining \n",
    "        if use_pretraining and batch_number > 0 and batch_number % pretraining_expand_depth_at == 0:\n",
    "            if classifier_depth < pretraining_max_depth:\n",
    "                classifier_depth += 1\n",
    "                classifier.initialize_block_weigths(classifier_depth, init_weights)\n",
    "        \n",
    "        # adapt learning rate\n",
    "        if batch_number > learning_rate_decay_after and batch_number % learning_rate_decay_at == 0:\n",
    "            learning_rate = learning_rate * learning_rate_decay_factor\n",
    "                                     \n",
    "    # finished training\n",
    "    file_name = training_out + '/' + str(int(time.time())) + '_' + str(model_number) + '_classifier_final.pth'\n",
    "    logging.info(\"Finished training, saved to file %s\"%(file_name))\n",
    "    torch.save(classifier.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Set up the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models and set evaluation mode\n",
    "\n",
    "# state transition\n",
    "transition = StateTransition(1 + 1 + 201, 64, 1)\n",
    "transition.load_state_dict(torch.load('transition/1552984806_0.000001/1552989898_1_transition_80000.pth'))\n",
    "estimator_depth = 2 \n",
    "\n",
    "transition.eval()\n",
    "\n",
    "# classifier\n",
    "classifier = Classifier(1, 64, 201) #128, 402)\n",
    "classifier.load_state_dict(torch.load('classifier/1552933539_0.057/1552965517_6_classifier_160000.pth'))  \n",
    "classifier_depth = 1\n",
    "\n",
    "classifier.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_evaluate_load_profile(battery_soc, battery_charging_efficiency, battery_discharging_efficiency, \n",
    "                  series_length, slot_length, tick_length, \n",
    "                  buffers, confidence,\n",
    "                  transition, estimator_depth, classifier, classifier_depth, state_mapping):\n",
    "    '''\n",
    "    \n",
    "    generates load profiles using the ANNs and evaluates the result.\n",
    "    \n",
    "    State post-processing:\n",
    "        - discretization\n",
    "    \n",
    "    '''        \n",
    "    \n",
    "    # bat_soc\n",
    "    current_state = torch.Tensor([battery_soc]).unsqueeze(0)\n",
    "    \n",
    "    buffer = torch.Tensor([0]).unsqueeze(0)\n",
    "    \n",
    "    # generate data\n",
    "    generated_states = []    \n",
    "    generated_data = None\n",
    "    action_history = []\n",
    "    for i in range(series_length):\n",
    "        generated_states.append(current_state.data.numpy()[0])\n",
    "        \n",
    "        # classify\n",
    "        out = classifier(current_state + buffer, classifier_depth)\n",
    "        if generated_data is None:\n",
    "            generated_data = out\n",
    "        else:\n",
    "            generated_data = torch.cat((generated_data, out), dim = 0)                \n",
    "            \n",
    "        # choose action\n",
    "        feasible_actions = np.where(torch.sigmoid(out.squeeze()).data.numpy() >= confidence)[0]\n",
    "        if len(feasible_actions) > 0:\n",
    "            action = np.random.choice(feasible_actions, 1)[0]\n",
    "        else:\n",
    "            action = np.argmax(torch.sigmoid(out.squeeze()).data.numpy())\n",
    "            #print('WARNING: all actions infeasible, defaulting to %d'%action)\n",
    "        \n",
    "        action_history.append(action)\n",
    "        \n",
    "        action_one_hot = np.zeros(out.size(1))\n",
    "        action_one_hot[action] = 1\n",
    "        input_one_hot = torch.Tensor(action_one_hot).view(1,-1)\n",
    "        input_external = torch.Tensor([0]).view(1,-1)        \n",
    "\n",
    "        current_state = transition(current_state, input_one_hot, input_external, estimator_depth)\n",
    "        \n",
    "        #\n",
    "        # <state post-processing>\n",
    "        #\n",
    "        # (discretization)\n",
    "        #\n",
    "        current_state[:,0] = torch.Tensor([state_mapping['discrete_socs'][np.digitize(current_state[:,0].detach().numpy(), \n",
    "                                                                                      state_mapping['discrete_socs_bins'])]]).unsqueeze(0)\n",
    "        #\n",
    "        # </state post-processing>\n",
    "        #\n",
    "\n",
    "    # test if generated profile is feasible\n",
    "    \n",
    "    def predetermined_strategy(time, delta_time, action_idxs, battery):\n",
    "        return action_history[time // slot_length]\n",
    "    \n",
    "    battery = systems.Battery(1, 1, 100, battery_soc, battery_charging_efficiency, battery_discharging_efficiency, 0, 0)\n",
    "\n",
    "    # run simulation\n",
    "    simulation = BatterySimulation(battery, predetermined_strategy)\n",
    "    simulation.run(tick_length, slot_length, series_length * slot_length)\n",
    "    \n",
    "    return [simulation.infeasibility_slot, np.array(simulation.load_profile), generated_states, generated_data, simulation.records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1924)\n",
    "\n",
    "confidence = 0.95\n",
    "\n",
    "#\n",
    "# Elements of the state are discretized\n",
    "#\n",
    "state_mapping = {\n",
    "    # discretization\n",
    "    'discrete_socs': np.linspace(0, 1, 1001)\n",
    "}\n",
    "\n",
    "state_mapping.update({\n",
    "    'discrete_socs_bins': [(a + b) / 2 for a, b in zip(state_mapping['discrete_socs'][:-1], state_mapping['discrete_socs'][1:])]\n",
    "})\n",
    "    \n",
    "# number of threads used for simulation\n",
    "simulation_thread_count = 1 # (more than 1 is slower)\n",
    "# number of simulations to run\n",
    "simulation_count = 1000\n",
    "\n",
    "# set up initial states for the simulation runs\n",
    "force_replace = False\n",
    "\n",
    "# don't apply here\n",
    "buffers = {'min_staying_time': (0,0), 'min_charge':0, 'max_charge':0} #(SLOT_LENGTH, SLOT_LENGTH),\n",
    "\n",
    "battery_soc_choices = np.random.choice(battery_socs, simulation_count, replace=(simulation_count>len(battery_socs) or force_replace))\n",
    "\n",
    "tasks = [{'battery_soc': battery_soc_choices[i], \n",
    "          'battery_charging_efficiency': battery_charging_efficiency, \n",
    "          'battery_discharging_efficiency': battery_discharging_efficiency, \n",
    "          'series_length': slot_count,\n",
    "          'tick_length': tick_length,\n",
    "          'slot_length': slot_length,\n",
    "          'buffers': buffers,\n",
    "          'confidence': confidence,\n",
    "          'transition': transition,\n",
    "          'estimator_depth': estimator_depth,\n",
    "          'classifier': classifier,\n",
    "          'classifier_depth': classifier_depth,\n",
    "          'state_mapping': state_mapping\n",
    "         } for i in range(simulation_count)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0ab34b9e53489e884c8e599fd637ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# perform evaluation\n",
    "\n",
    "# !!!\n",
    "# Attention: For reproducible results make sure to run the previous code block before running this block\n",
    "# !!!\n",
    "\n",
    "\n",
    "# !!!\n",
    "# Attention: Code is not optimized for multiprocessing! This is faster than using a multiprocessing pool.\n",
    "#\n",
    "# From the pytorch documentation: \"Sharing CUDA tensors between processes is supported only in Python 3, using a spawn or forkserver start methods.\"\n",
    "#\n",
    "# On Unix \"fork\" is standard. Options \"spawn\" and \"forkserver\"  didn't work in jupyter lab.\n",
    "# !!!\n",
    "\n",
    "results = []\n",
    "with tqdm(total=simulation_count) as pbar:\n",
    "    for task in tasks:\n",
    "        results.append(generate_and_evaluate_load_profile(**task))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 983 feasible profiles\n",
      "Slot of infeasibility:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infeasible profile indices:\n",
      "[ 93 137 173 358 426 471 567 638 644 679 717 725 848 849 851 866 889]\n"
     ]
    }
   ],
   "source": [
    "hist_data = [results[i][0] for i in range(len(results))]\n",
    "print('Generated %d feasible profiles'%sum([i<0 for i in hist_data]))\n",
    "\n",
    "print('Slot of infeasibility:')\n",
    "fig = figure(figsize=(25,7))\n",
    "fig.set_facecolor('white')\n",
    "ax = subplot(121)\n",
    "ax.set_title('Simulation result')\n",
    "ax.hist(hist_data, 97)\n",
    "plt.show()\n",
    "\n",
    "print('Infeasible profile indices:')\n",
    "print(np.array([i for i in range(len(hist_data)) if hist_data[i]>=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with confidence 0.950000\n",
      "false positives: 3018, 0.000156\n",
      "false negatives: 80416, 0.004167\n",
      "correctly classified: 19212566, 0.995676\n"
     ]
    }
   ],
   "source": [
    "#print('buffers %s'%str(buffers)) # don't apply\n",
    "print('with confidence %f'%(confidence))\n",
    "\n",
    "false_positives = 0\n",
    "false_negatives = 0\n",
    "total_number = 0\n",
    "\n",
    "for result in results:\n",
    "    simulated_data = []\n",
    "    for i in range(slot_count):\n",
    "        slot_data = np.zeros(len(result[3][0]))\n",
    "        slot_data[result[-1][i][\"feasible_actions\"]] = 1\n",
    "        simulated_data.append(slot_data)\n",
    "    simulated_data = np.array(simulated_data)\n",
    "    difference = (torch.sigmoid(result[3]) >= confidence).data.numpy().round() - simulated_data\n",
    "    false_positives += sum(difference > 0)\n",
    "    false_negatives += sum(difference < 0)\n",
    "    total_number += len(result[3]) * len(result[3][0])\n",
    "\n",
    "print('false positives: %d, %f'%(false_positives, false_positives/total_number))\n",
    "print('false negatives: %d, %f'%(false_negatives, false_negatives/total_number))\n",
    "print('correctly classified: %d, %f'%(total_number-false_positives-false_negatives, (total_number-false_positives-false_negatives)/total_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation details\n",
    "\n",
    "The following code can be used to look into the details of an individual simulation run. Simply specify the idx at the beginning of the next code block.\n",
    "\n",
    "The plots show the feasibility of actions for each time slot. Dark areas are infeasible actions. Please keep in mind, that the feasibility of actions depends on the state which in turn depends on the load profile, i.e., the performed actions. The respective load profile is plotted in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state\n",
      "{'state': (0.84,), 'feasible_actions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168], 'action_choice': 66, 'external_input': 0, 'debugging_info': None}\n",
      "id 0, soc 0.840000, infeasibility @-1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation Delta\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x1008 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# index of simulation run\n",
    "idx = 0\n",
    "\n",
    "# confidence used for plotting\n",
    "plot_confidence = 0.85\n",
    "\n",
    "# plot design\n",
    "standard_cmap = matplotlib.colors.LinearSegmentedColormap.from_list('standard', ['#663854', '#BEBEBE', '#FAFAD2'])\n",
    "delta_cmap = matplotlib.colors.LinearSegmentedColormap.from_list('delta', ['#6082B6', '#FAFAD2', '#E66771'])\n",
    "\n",
    "# dataset parameters\n",
    "number_of_actions = len(results[idx][3][0])\n",
    "\n",
    "print('Initial state')\n",
    "print(results[idx][-1][0])\n",
    "\n",
    "actions = [results[idx][-1][i][\"action_choice\"] for i in range(slot_count)]\n",
    "\n",
    "generated_data = results[idx][3]\n",
    "simulated_data = []\n",
    "for i in range(slot_count):\n",
    "    slot_data = np.zeros(number_of_actions)\n",
    "    slot_data[results[idx][-1][i][\"feasible_actions\"]] = 1\n",
    "    simulated_data.append(slot_data)\n",
    "simulated_data = np.array(simulated_data)\n",
    "\n",
    "infeasible_at = results[idx][0]\n",
    "print('id %d, soc %f, infeasibility @%d'%(idx, results[idx][-1][0][\"state\"][0], infeasible_at))\n",
    "\n",
    "fig = figure(figsize=(25,7))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "ax = subplot(121)\n",
    "ax.set_title('Generation Output')\n",
    "ax.imshow(torch.sigmoid(generated_data).data.numpy().transpose(), cmap=standard_cmap, origin='lower', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "ax2 = subplot(122)\n",
    "ax2.set_title('Simulated Data')\n",
    "ax2.step(range(0,96), actions, 'r', where='mid')\n",
    "ax2.imshow(simulated_data.transpose(), cmap=standard_cmap, origin='lower', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Generation Delta')\n",
    "fig = figure(figsize=(25,14))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "ax = subplot(121)\n",
    "ax.set_title('Delta, Generation Model >= %f & Real Data'%plot_confidence)\n",
    "ax.imshow((torch.sigmoid(generated_data) >= plot_confidence).data.numpy().round().transpose() - simulated_data.transpose(), cmap=delta_cmap, origin='lower', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.step(range(0,96), actions, 'r', where='mid')\n",
    "\n",
    "ax2 = subplot(122)\n",
    "ax2.set_title('Delta, Generation Model >= %f & Real Data'%confidence)\n",
    "ax2.imshow((torch.sigmoid(generated_data) >= confidence).data.numpy().round().transpose() - simulated_data.transpose(), cmap=delta_cmap, origin='lower', aspect='auto', vmin=-1, vmax=1)\n",
    "ax2.step(range(0,96), actions, 'r', where='mid')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot -1\n",
      "Sim: {'state': (0.4728,), 'feasible_actions': None, 'action_choice': None, 'external_input': None, 'debugging_info': None}\n",
      "Gen: [0.595]\n",
      "tensor([0.9900, 0.9899, 0.9899, 0.9899, 0.9902, 0.9901, 0.9901, 0.9900, 0.9900,\n",
      "        0.9900, 0.9900, 0.9900, 0.9900, 0.9900, 0.9901, 0.9901, 0.9901, 0.9900,\n",
      "        0.9900, 0.9899, 0.9899, 0.9899, 0.9901, 0.9900, 0.9899, 0.9899, 0.9900,\n",
      "        0.9900, 0.9901, 0.9899, 0.9900, 0.9900, 0.9899, 0.9901, 0.9898, 0.9899,\n",
      "        0.9900, 0.9897, 0.9898, 0.9899, 0.9902, 0.9900, 0.9902, 0.9901, 0.9899,\n",
      "        0.9900, 0.9899, 0.9900, 0.9899, 0.9900, 0.9900, 0.9900, 0.9899, 0.9900,\n",
      "        0.9898, 0.9899, 0.9901, 0.9900, 0.9901, 0.9900, 0.9898, 0.9899, 0.9900,\n",
      "        0.9899, 0.9898, 0.9899, 0.9897, 0.9900, 0.9900, 0.9901, 0.9901, 0.9900,\n",
      "        0.9900, 0.9900, 0.9900, 0.9899, 0.9900, 0.9900, 0.9902, 0.9902, 0.9902,\n",
      "        0.9901, 0.9899, 0.9898, 0.9900, 0.9900, 0.9899, 0.9900, 0.9900, 0.9900,\n",
      "        0.9900, 0.9899, 0.9898, 0.9902, 0.9901, 0.9901, 0.9900, 0.9898, 0.9899,\n",
      "        0.9897, 0.9900, 0.9898, 0.9899, 0.9897, 0.9900, 0.9900, 0.9900, 0.9899,\n",
      "        0.9899, 0.9900, 0.9900, 0.9899, 0.9900, 0.9901, 0.9900, 0.9901, 0.9900,\n",
      "        0.9901, 0.9898, 0.9900, 0.9901, 0.9901, 0.9898, 0.9898, 0.9900, 0.9897,\n",
      "        0.9902, 0.9900, 0.9899, 0.9901, 0.9899, 0.9902, 0.9900, 0.9899, 0.9901,\n",
      "        0.9902, 0.9898, 0.9900, 0.9901, 0.9901, 0.9899, 0.9904, 0.9899, 0.9900,\n",
      "        0.9899, 0.9900, 0.9901, 0.9899, 0.9900, 0.9899, 0.9900, 0.9898, 0.9898,\n",
      "        0.9899, 0.9906, 0.9901, 0.9903, 0.9902, 0.9903, 0.9903, 0.9902, 0.9901,\n",
      "        0.9902, 0.9904, 0.9900, 0.9900, 0.9899, 0.9901, 0.9901, 0.9901, 0.9904,\n",
      "        0.9904, 0.9906, 0.9900, 0.9900, 0.9900, 0.9899, 0.9897, 0.9896, 0.9895,\n",
      "        0.9896, 0.9899, 0.9899, 0.9898, 0.9897, 0.9898, 0.9897, 0.9898, 0.9897,\n",
      "        0.9899, 0.9901, 0.9900, 0.9899, 0.9901, 0.9907, 0.9909, 0.9907, 0.9907,\n",
      "        0.9900, 0.9901, 0.9900], grad_fn=<SigmoidBackward>)\n",
      "Rating of chosen action: tensor([[0.9900, 0.9899, 0.9899, 0.9899, 0.9902, 0.9901, 0.9901, 0.9900, 0.9900,\n",
      "         0.9900, 0.9900, 0.9900, 0.9900, 0.9900, 0.9901, 0.9901, 0.9901, 0.9900,\n",
      "         0.9900, 0.9899, 0.9899, 0.9899, 0.9901, 0.9900, 0.9899, 0.9899, 0.9900,\n",
      "         0.9900, 0.9901, 0.9899, 0.9900, 0.9900, 0.9899, 0.9901, 0.9898, 0.9899,\n",
      "         0.9900, 0.9897, 0.9898, 0.9899, 0.9902, 0.9900, 0.9902, 0.9901, 0.9899,\n",
      "         0.9900, 0.9899, 0.9900, 0.9899, 0.9900, 0.9900, 0.9900, 0.9899, 0.9900,\n",
      "         0.9898, 0.9899, 0.9901, 0.9900, 0.9901, 0.9900, 0.9898, 0.9899, 0.9900,\n",
      "         0.9899, 0.9898, 0.9899, 0.9897, 0.9900, 0.9900, 0.9901, 0.9901, 0.9900,\n",
      "         0.9900, 0.9900, 0.9900, 0.9899, 0.9900, 0.9900, 0.9902, 0.9902, 0.9902,\n",
      "         0.9901, 0.9899, 0.9898, 0.9900, 0.9900, 0.9899, 0.9900, 0.9900, 0.9900,\n",
      "         0.9900, 0.9899, 0.9898, 0.9902, 0.9901, 0.9901, 0.9900, 0.9898, 0.9899,\n",
      "         0.9897, 0.9900, 0.9898, 0.9899, 0.9897, 0.9900, 0.9900, 0.9900, 0.9899,\n",
      "         0.9899, 0.9900, 0.9900, 0.9899, 0.9900, 0.9901, 0.9900, 0.9901, 0.9900,\n",
      "         0.9901, 0.9898, 0.9900, 0.9901, 0.9901, 0.9898, 0.9898, 0.9900, 0.9897,\n",
      "         0.9902, 0.9900, 0.9899, 0.9901, 0.9899, 0.9902, 0.9900, 0.9899, 0.9901,\n",
      "         0.9902, 0.9898, 0.9900, 0.9901, 0.9901, 0.9899, 0.9904, 0.9899, 0.9900,\n",
      "         0.9899, 0.9900, 0.9901, 0.9899, 0.9900, 0.9899, 0.9900, 0.9898, 0.9898,\n",
      "         0.9899, 0.9906, 0.9901, 0.9903, 0.9902, 0.9903, 0.9903, 0.9902, 0.9901,\n",
      "         0.9902, 0.9904, 0.9900, 0.9900, 0.9899, 0.9901, 0.9901, 0.9901, 0.9904,\n",
      "         0.9904, 0.9906, 0.9900, 0.9900, 0.9900, 0.9899, 0.9897, 0.9896, 0.9895,\n",
      "         0.9896, 0.9899, 0.9899, 0.9898, 0.9897, 0.9898, 0.9897, 0.9898, 0.9897,\n",
      "         0.9899, 0.9901, 0.9900, 0.9899, 0.9901, 0.9907, 0.9909, 0.9907, 0.9907,\n",
      "         0.9900, 0.9901, 0.9900]], grad_fn=<SigmoidBackward>)\n",
      "slot 0\n",
      "Sim: {'state': (0.84,), 'feasible_actions': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168], 'action_choice': 66, 'external_input': 0, 'debugging_info': None}\n",
      "Gen: [0.84]\n",
      "tensor([9.8963e-01, 9.9049e-01, 9.9019e-01, 9.9092e-01, 9.8891e-01, 9.8974e-01,\n",
      "        9.8965e-01, 9.8928e-01, 9.8928e-01, 9.8945e-01, 9.8914e-01, 9.8914e-01,\n",
      "        9.8918e-01, 9.8974e-01, 9.9090e-01, 9.9027e-01, 9.8964e-01, 9.8855e-01,\n",
      "        9.9022e-01, 9.9057e-01, 9.8977e-01, 9.9044e-01, 9.8907e-01, 9.8980e-01,\n",
      "        9.9028e-01, 9.9095e-01, 9.9004e-01, 9.8858e-01, 9.9089e-01, 9.8924e-01,\n",
      "        9.8919e-01, 9.8944e-01, 9.8946e-01, 9.9000e-01, 9.9036e-01, 9.8916e-01,\n",
      "        9.9049e-01, 9.9056e-01, 9.9064e-01, 9.8927e-01, 9.8959e-01, 9.8909e-01,\n",
      "        9.9077e-01, 9.8966e-01, 9.8978e-01, 9.9004e-01, 9.8997e-01, 9.8803e-01,\n",
      "        9.9026e-01, 9.9018e-01, 9.9016e-01, 9.9046e-01, 9.8963e-01, 9.8888e-01,\n",
      "        9.8853e-01, 9.9107e-01, 9.8959e-01, 9.8945e-01, 9.9125e-01, 9.8975e-01,\n",
      "        9.8909e-01, 9.9036e-01, 9.9039e-01, 9.8991e-01, 9.8959e-01, 9.8983e-01,\n",
      "        9.9046e-01, 9.8984e-01, 9.9037e-01, 9.9064e-01, 9.8928e-01, 9.8956e-01,\n",
      "        9.8920e-01, 9.8920e-01, 9.8916e-01, 9.8957e-01, 9.8945e-01, 9.8916e-01,\n",
      "        9.8972e-01, 9.9078e-01, 9.8952e-01, 9.8915e-01, 9.9014e-01, 9.9097e-01,\n",
      "        9.9118e-01, 9.8920e-01, 9.9011e-01, 9.8912e-01, 9.8952e-01, 9.9113e-01,\n",
      "        9.8935e-01, 9.8991e-01, 9.8984e-01, 9.8886e-01, 9.8948e-01, 9.8941e-01,\n",
      "        9.8984e-01, 9.9100e-01, 9.9088e-01, 9.9078e-01, 9.8918e-01, 9.8979e-01,\n",
      "        9.8796e-01, 9.8887e-01, 9.8550e-01, 9.8125e-01, 9.9292e-01, 9.8822e-01,\n",
      "        9.9065e-01, 9.8943e-01, 9.9554e-01, 9.9094e-01, 9.9299e-01, 9.7904e-01,\n",
      "        9.8611e-01, 9.9548e-01, 9.8558e-01, 9.8449e-01, 9.9166e-01, 9.9344e-01,\n",
      "        9.9059e-01, 9.8142e-01, 9.9864e-01, 9.9340e-01, 9.7981e-01, 9.9192e-01,\n",
      "        9.9219e-01, 9.8724e-01, 9.9224e-01, 9.8836e-01, 9.8383e-01, 9.8802e-01,\n",
      "        9.8820e-01, 9.9163e-01, 9.9117e-01, 9.9096e-01, 9.9089e-01, 9.9571e-01,\n",
      "        9.8767e-01, 9.9648e-01, 9.8904e-01, 9.8551e-01, 9.9499e-01, 9.8778e-01,\n",
      "        9.8243e-01, 9.8580e-01, 9.8511e-01, 9.8821e-01, 9.8718e-01, 9.8809e-01,\n",
      "        9.8600e-01, 9.8805e-01, 9.9615e-01, 9.9294e-01, 9.9005e-01, 9.9381e-01,\n",
      "        9.8962e-01, 9.8796e-01, 9.9150e-01, 9.9202e-01, 9.9989e-01, 9.9986e-01,\n",
      "        9.9987e-01, 9.9990e-01, 9.6132e-01, 9.6208e-01, 9.6049e-01, 9.6429e-01,\n",
      "        9.6590e-01, 5.8607e-02, 5.3417e-02, 4.7225e-02, 4.2768e-02, 3.6935e-04,\n",
      "        2.6894e-04, 3.4104e-04, 5.1417e-04, 1.9787e-05, 1.1803e-04, 1.0016e-04,\n",
      "        5.1195e-05, 1.0540e-02, 1.0592e-02, 1.2833e-02, 1.3018e-02, 1.2684e-02,\n",
      "        1.0115e-02, 9.2202e-03, 1.1806e-02, 7.5967e-03, 1.4683e-02, 2.1430e-02,\n",
      "        1.4202e-02, 1.5044e-02, 1.1403e-02, 1.5516e-02, 1.3008e-02, 1.2787e-02,\n",
      "        1.5980e-02, 1.5024e-02, 1.6576e-02], grad_fn=<SigmoidBackward>)\n",
      "Rating of chosen action: tensor(0.9905, grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "start_slot = infeasible_at\n",
    "end_slot = start_slot + 1\n",
    "\n",
    "#start_slot = 0\n",
    "#end_slot = 10\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for i in range(start_slot, end_slot+1):\n",
    "    print('slot %d'%i)\n",
    "    print('Sim:',end=\" \")\n",
    "    print(results[idx][-1][i])\n",
    "    print('Gen:',end=\" \")\n",
    "    print(np.array2string(np.around(results[idx][2][i],4), separator=', '))\n",
    "    print(torch.sigmoid(results[idx][3][i]))\n",
    "    print('Rating of chosen action:',end=\" \")\n",
    "    print(torch.sigmoid(results[idx][3][i][results[idx][-1][i]['action_choice']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84]\n",
      "[0.749601]\n",
      "[0.75]\n"
     ]
    }
   ],
   "source": [
    "slot = 0\n",
    "\n",
    "input_state = torch.Tensor(results[idx][2][slot]).unsqueeze(0)\n",
    "input_one_hot = torch.zeros(number_of_actions)\n",
    "input_one_hot[results[idx][-1][slot]['action_choice']] = 1\n",
    "input_one_hot = input_one_hot.unsqueeze(0)\n",
    "input_external = torch.Tensor([results[idx][-1][slot]['external_input']]).unsqueeze(0)\n",
    "\n",
    "print(input_state.data.numpy()[0])\n",
    "\n",
    "print(transition(input_state, input_one_hot, input_external, estimator_depth).data.numpy()[0])\n",
    "print(results[idx][2][slot+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
